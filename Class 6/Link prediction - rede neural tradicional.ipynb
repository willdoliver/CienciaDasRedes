{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.nn import Sequential, ReLU, Linear\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708])\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "print(data)\n",
    "data.train_mask = data.val_mask = data.test_mask = None\n",
    "print(data)\n",
    "\n",
    "\n",
    "transform = T.RandomLinkSplit(is_undirected=True,add_negative_train_samples=True)\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "train_data = train_data.to(device)\n",
    "val_data=val_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "\n",
    "# test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward(torch.nn.Module):\n",
    "    \n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Feedforward, self).__init__()\n",
    "            \n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            \n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "            self.fc3 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "            self.fc4 = torch.nn.Linear(self.hidden_size, 1)\n",
    "            \n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.out_act = nn.Sigmoid()\n",
    "            \n",
    "            \n",
    "        def forward(self, x):\n",
    "            output = self.fc1(x)\n",
    "            output = self.relu(output)\n",
    "            \n",
    "            output = self.fc2(output)\n",
    "            output = self.relu(output)\n",
    "            \n",
    "            output = self.fc3(output)\n",
    "            output = self.relu(output)\n",
    "            \n",
    "            output = self.fc4(output)\n",
    "            \n",
    "            output = self.out_act(output)\n",
    "\n",
    "            return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando features que representam as arestas: soma das features dos nós"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2110, 1433])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = train_data.x.shape[1]\n",
    "\n",
    "## Gerando as features para o treino\n",
    "featuresEdges_treino = \"\"\n",
    "\n",
    "totalEdges_treino = train_data.edge_label_index.shape[1]\n",
    "\n",
    "for col in range(0,totalEdges_treino):\n",
    "    node1 = train_data.edge_label_index[0,col]\n",
    "    node2 = train_data.edge_label_index[1,col]\n",
    "    \n",
    "    vals1 = train_data.x[[node1,]]\n",
    "    vals1 = torch.reshape(vals1, (1, num_features))\n",
    "    \n",
    "    vals2 = train_data.x[[node2,]]\n",
    "    vals2 = torch.reshape(vals2, (1, num_features))\n",
    "    \n",
    "    if col == 0:\n",
    "        featuresEdges_treino = vals1+vals2\n",
    "        continue\n",
    "        \n",
    "    somado = vals1+vals2\n",
    "    \n",
    "    featuresEdges_treino =  torch.cat((featuresEdges_treino, somado), dim=0) \n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "##Gerando as features para o teste\n",
    "featuresEdges_teste = \"\"\n",
    "\n",
    "totalEdges_teste = test_data.edge_label_index.shape[1]\n",
    "print(totalEdges_teste)\n",
    "for col in range(0,totalEdges_teste):\n",
    "\n",
    "    node1 = test_data.edge_label_index[0,col]\n",
    "    node2 = test_data.edge_label_index[1,col]\n",
    "    \n",
    "    vals1 = test_data.x[[node1,]]\n",
    "    vals1 = torch.reshape(vals1, (1, num_features))\n",
    "\n",
    "    vals2 = test_data.x[[node2,]]\n",
    "    vals2 = torch.reshape(vals2, (1, num_features))\n",
    "    \n",
    "    if col == 0:\n",
    "        featuresEdges_teste = vals1+vals2\n",
    "        continue\n",
    "        \n",
    "    somado = vals1+vals2\n",
    "    \n",
    "    featuresEdges_teste =  torch.cat((featuresEdges_teste, somado), dim=0) \n",
    "\n",
    "featuresEdges_teste.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instância do modelo e outros parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedforward(\n",
      "  (fc1): Linear(in_features=1433, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (out_act): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_features = train_data.x.shape[1]\n",
    "hidden_channel = 64\n",
    "\n",
    "#input = (número de features), e hidden size = 10 (número de neurôneos na camada escondida)\n",
    "model = Feedforward(num_features, hidden_channel).to(device)\n",
    "print(model)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste - perda antes do treinamento 0.6944001317024231\n",
      "Epoch 0: perda treino: 0.6944001317024231\n",
      "Epoch 1: perda treino: 0.6896529197692871\n",
      "Epoch 2: perda treino: 0.6757488250732422\n",
      "Epoch 3: perda treino: 0.6507232785224915\n",
      "Epoch 4: perda treino: 0.6165645718574524\n",
      "Epoch 5: perda treino: 0.5855273008346558\n",
      "Epoch 6: perda treino: 0.5854929685592651\n",
      "Epoch 7: perda treino: 0.5627989768981934\n",
      "Epoch 8: perda treino: 0.5632736682891846\n",
      "Epoch 9: perda treino: 0.5038442611694336\n",
      "Epoch 10: perda treino: 0.5090611577033997\n",
      "Epoch 11: perda treino: 0.4494154751300812\n",
      "Epoch 12: perda treino: 0.431398868560791\n",
      "Epoch 13: perda treino: 0.4035916030406952\n",
      "Epoch 14: perda treino: 0.3546677529811859\n",
      "Epoch 15: perda treino: 0.33595922589302063\n",
      "Epoch 16: perda treino: 0.2856478691101074\n",
      "Epoch 17: perda treino: 0.2637999355792999\n",
      "Epoch 18: perda treino: 0.23194469511508942\n",
      "Epoch 19: perda treino: 0.19474805891513824\n",
      "Epoch 20: perda treino: 0.17337380349636078\n",
      "Epoch 21: perda treino: 0.13761265575885773\n",
      "Epoch 22: perda treino: 0.12373838573694229\n",
      "Epoch 23: perda treino: 0.09340933710336685\n",
      "Epoch 24: perda treino: 0.07996606081724167\n",
      "Epoch 25: perda treino: 0.06533391773700714\n",
      "Epoch 26: perda treino: 0.05095381289720535\n",
      "Epoch 27: perda treino: 0.04079342633485794\n",
      "Epoch 28: perda treino: 0.03123464062809944\n",
      "Epoch 29: perda treino: 0.024329930543899536\n",
      "Epoch 30: perda treino: 0.01967652514576912\n",
      "Epoch 31: perda treino: 0.013895370066165924\n",
      "Epoch 32: perda treino: 0.011836458928883076\n",
      "Epoch 33: perda treino: 0.009574873372912407\n",
      "Epoch 34: perda treino: 0.007240918930619955\n",
      "Epoch 35: perda treino: 0.0061144838109612465\n",
      "Epoch 36: perda treino: 0.004954935517162085\n",
      "Epoch 37: perda treino: 0.0040270667523145676\n",
      "Epoch 38: perda treino: 0.003588699735701084\n",
      "Epoch 39: perda treino: 0.003285248763859272\n",
      "Epoch 40: perda treino: 0.0028678053058683872\n",
      "Epoch 41: perda treino: 0.0023869648575782776\n",
      "Epoch 42: perda treino: 0.0019586978014558554\n",
      "Epoch 43: perda treino: 0.0017361055361106992\n",
      "Epoch 44: perda treino: 0.0015590371331200004\n",
      "Epoch 45: perda treino: 0.0013857361627742648\n",
      "Epoch 46: perda treino: 0.0012110137613490224\n",
      "Epoch 47: perda treino: 0.001066807541064918\n",
      "Epoch 48: perda treino: 0.0008552769431844354\n",
      "Epoch 49: perda treino: 0.0007041100761853158\n",
      "Epoch 50: perda treino: 0.0006132785929366946\n",
      "Epoch 51: perda treino: 0.0005692595150321722\n",
      "Epoch 52: perda treino: 0.0005492789205163717\n",
      "Epoch 53: perda treino: 0.0005347695550881326\n",
      "Epoch 54: perda treino: 0.0005195096600800753\n",
      "Epoch 55: perda treino: 0.0005038235103711486\n",
      "Epoch 56: perda treino: 0.0004891127464361489\n",
      "Epoch 57: perda treino: 0.00047699265996925533\n",
      "Epoch 58: perda treino: 0.00046734968782402575\n",
      "Epoch 59: perda treino: 0.000459937407867983\n",
      "Epoch 60: perda treino: 0.0004540980444289744\n",
      "Epoch 61: perda treino: 0.000449212733656168\n",
      "Epoch 62: perda treino: 0.0004449272237252444\n",
      "Epoch 63: perda treino: 0.0004410261462908238\n",
      "Epoch 64: perda treino: 0.0004375231801532209\n",
      "Epoch 65: perda treino: 0.0004344211774878204\n",
      "Epoch 66: perda treino: 0.0004316162085160613\n",
      "Epoch 67: perda treino: 0.0004290713695809245\n",
      "Epoch 68: perda treino: 0.0004266981559339911\n",
      "Epoch 69: perda treino: 0.00042442712583579123\n",
      "Epoch 70: perda treino: 0.0004222285351715982\n",
      "Epoch 71: perda treino: 0.0004200614639557898\n",
      "Epoch 72: perda treino: 0.0004178820236120373\n",
      "Epoch 73: perda treino: 0.00041567583684809506\n",
      "Epoch 74: perda treino: 0.00041342282202094793\n",
      "Epoch 75: perda treino: 0.0004111018206458539\n",
      "Epoch 76: perda treino: 0.0004087066336069256\n",
      "Epoch 77: perda treino: 0.0004062222724314779\n",
      "Epoch 78: perda treino: 0.0004036193713545799\n",
      "Epoch 79: perda treino: 0.00040086882654577494\n",
      "Epoch 80: perda treino: 0.00039795288466848433\n",
      "Epoch 81: perda treino: 0.0003948457015212625\n",
      "Epoch 82: perda treino: 0.00039153112447820604\n",
      "Epoch 83: perda treino: 0.00038799236062914133\n",
      "Epoch 84: perda treino: 0.0003848815686069429\n",
      "Epoch 85: perda treino: 0.00038023671368137\n",
      "Epoch 86: perda treino: 0.0003759826940950006\n",
      "Epoch 87: perda treino: 0.0003714350750669837\n",
      "Epoch 88: perda treino: 0.00036658119643107057\n",
      "Epoch 89: perda treino: 0.00036141107557341456\n",
      "Epoch 90: perda treino: 0.0003559101605787873\n",
      "Epoch 91: perda treino: 0.0003500489692669362\n",
      "Epoch 92: perda treino: 0.0003438376297708601\n",
      "Epoch 93: perda treino: 0.00033727361005730927\n",
      "Epoch 94: perda treino: 0.0003303564735688269\n",
      "Epoch 95: perda treino: 0.0003230878501199186\n",
      "Epoch 96: perda treino: 0.0003154708829242736\n",
      "Epoch 97: perda treino: 0.00030750929727219045\n",
      "Epoch 98: perda treino: 0.0002992121153511107\n",
      "Epoch 99: perda treino: 0.0002905894652940333\n",
      "Epoch 100: perda treino: 0.0002816538908518851\n",
      "Epoch 101: perda treino: 0.00027242532814852893\n",
      "Epoch 102: perda treino: 0.00026304429047740996\n",
      "Epoch 103: perda treino: 0.00025367538910359144\n",
      "Epoch 104: perda treino: 0.0002458897652104497\n",
      "Epoch 105: perda treino: 0.000234531908063218\n",
      "Epoch 106: perda treino: 0.00022473711578641087\n",
      "Epoch 107: perda treino: 0.00021466314501594752\n",
      "Epoch 108: perda treino: 0.0002044178545475006\n",
      "Epoch 109: perda treino: 0.00019406313367653638\n",
      "Epoch 110: perda treino: 0.00018365787400398403\n",
      "Epoch 111: perda treino: 0.00017343234503641725\n",
      "Epoch 112: perda treino: 0.00016503453662153333\n",
      "Epoch 113: perda treino: 0.00015789842291269451\n",
      "Epoch 114: perda treino: 0.00015142347547225654\n",
      "Epoch 115: perda treino: 0.0001452332071494311\n",
      "Epoch 116: perda treino: 0.00013941885845270008\n",
      "Epoch 117: perda treino: 0.0001344825723208487\n",
      "Epoch 118: perda treino: 0.00013171372120268643\n",
      "Epoch 119: perda treino: 0.00012981813051737845\n",
      "Epoch 120: perda treino: 0.00012795340444426984\n",
      "Epoch 121: perda treino: 0.00012612287537194788\n",
      "Epoch 122: perda treino: 0.00012487451022025198\n",
      "Epoch 123: perda treino: 0.00012374273501336575\n",
      "Epoch 124: perda treino: 0.00012266064004506916\n",
      "Epoch 125: perda treino: 0.00012163138308096677\n",
      "Epoch 126: perda treino: 0.00012060857989126816\n",
      "Epoch 127: perda treino: 0.00011958534742007032\n",
      "Epoch 128: perda treino: 0.00011845625704154372\n",
      "Epoch 129: perda treino: 0.0001172718548332341\n",
      "Epoch 130: perda treino: 0.00011605163308558986\n",
      "Epoch 131: perda treino: 0.00011480863759061322\n",
      "Epoch 132: perda treino: 0.00011355151946190745\n",
      "Epoch 133: perda treino: 0.00011228642688365653\n",
      "Epoch 134: perda treino: 0.00011101766722276807\n",
      "Epoch 135: perda treino: 0.00010974847828038037\n",
      "Epoch 136: perda treino: 0.00010848183592315763\n",
      "Epoch 137: perda treino: 0.00010722061415435746\n",
      "Epoch 138: perda treino: 0.00010596561332931742\n",
      "Epoch 139: perda treino: 0.00010471755376784131\n",
      "Epoch 140: perda treino: 0.00010347865463700145\n",
      "Epoch 141: perda treino: 0.00010224993457086384\n",
      "Epoch 142: perda treino: 0.00010103077511303127\n",
      "Epoch 143: perda treino: 9.982221672544256e-05\n",
      "Epoch 144: perda treino: 9.862466686172411e-05\n",
      "Epoch 145: perda treino: 9.743814007379115e-05\n",
      "Epoch 146: perda treino: 9.626149403629825e-05\n",
      "Epoch 147: perda treino: 9.509695519227535e-05\n",
      "Epoch 148: perda treino: 9.394333756063133e-05\n",
      "Epoch 149: perda treino: 9.280056838179007e-05\n",
      "Epoch 150: perda treino: 9.166804375126958e-05\n",
      "Epoch 151: perda treino: 9.054576366906986e-05\n",
      "Epoch 152: perda treino: 8.943409920902923e-05\n",
      "Epoch 153: perda treino: 8.833185711409897e-05\n",
      "Epoch 154: perda treino: 8.72393065947108e-05\n",
      "Epoch 155: perda treino: 8.615585102234036e-05\n",
      "Epoch 156: perda treino: 8.508069004165009e-05\n",
      "Epoch 157: perda treino: 8.401416562264785e-05\n",
      "Epoch 158: perda treino: 8.29546625027433e-05\n",
      "Epoch 159: perda treino: 8.19021588540636e-05\n",
      "Epoch 160: perda treino: 8.085588342510164e-05\n",
      "Epoch 161: perda treino: 7.981412636581808e-05\n",
      "Epoch 162: perda treino: 7.877537427702919e-05\n",
      "Epoch 163: perda treino: 7.773856486892328e-05\n",
      "Epoch 164: perda treino: 7.670083141420037e-05\n",
      "Epoch 165: perda treino: 7.566060230601579e-05\n",
      "Epoch 166: perda treino: 7.461473433068022e-05\n",
      "Epoch 167: perda treino: 7.35604262445122e-05\n",
      "Epoch 168: perda treino: 7.249359623529017e-05\n",
      "Epoch 169: perda treino: 7.140912930481136e-05\n",
      "Epoch 170: perda treino: 7.030538108665496e-05\n",
      "Epoch 171: perda treino: 6.917784048710018e-05\n",
      "Epoch 172: perda treino: 6.802276038797572e-05\n",
      "Epoch 173: perda treino: 6.68413849780336e-05\n",
      "Epoch 174: perda treino: 6.563494389411062e-05\n",
      "Epoch 175: perda treino: 6.441066216211766e-05\n",
      "Epoch 176: perda treino: 6.317502993624657e-05\n",
      "Epoch 177: perda treino: 6.193718581926078e-05\n",
      "Epoch 178: perda treino: 6.0708953242283314e-05\n",
      "Epoch 179: perda treino: 5.950354170636274e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180: perda treino: 5.833375689690001e-05\n",
      "Epoch 181: perda treino: 5.720705303247087e-05\n",
      "Epoch 182: perda treino: 5.612508539343253e-05\n",
      "Epoch 183: perda treino: 5.508233152795583e-05\n",
      "Epoch 184: perda treino: 5.4065254516899586e-05\n",
      "Epoch 185: perda treino: 5.305963713908568e-05\n",
      "Epoch 186: perda treino: 5.205262277740985e-05\n",
      "Epoch 187: perda treino: 5.1048205932602286e-05\n",
      "Epoch 188: perda treino: 5.006243009120226e-05\n",
      "Epoch 189: perda treino: 4.911549331154674e-05\n",
      "Epoch 190: perda treino: 4.82190735056065e-05\n",
      "Epoch 191: perda treino: 4.737402923638001e-05\n",
      "Epoch 192: perda treino: 4.656937744584866e-05\n",
      "Epoch 193: perda treino: 4.579011874739081e-05\n",
      "Epoch 194: perda treino: 4.501891817199066e-05\n",
      "Epoch 195: perda treino: 4.424925646162592e-05\n",
      "Epoch 196: perda treino: 4.34839676017873e-05\n",
      "Epoch 197: perda treino: 4.27299746661447e-05\n",
      "Epoch 198: perda treino: 4.199907198199071e-05\n",
      "Epoch 199: perda treino: 4.1298786527477205e-05\n",
      "Epoch 200: perda treino: 4.062649531988427e-05\n",
      "Epoch 201: perda treino: 3.997472595074214e-05\n",
      "Epoch 202: perda treino: 3.932431718567386e-05\n",
      "Epoch 203: perda treino: 3.86687352147419e-05\n",
      "Epoch 204: perda treino: 3.801240018219687e-05\n",
      "Epoch 205: perda treino: 3.736351936822757e-05\n",
      "Epoch 206: perda treino: 3.673044193419628e-05\n",
      "Epoch 207: perda treino: 3.611587089835666e-05\n",
      "Epoch 208: perda treino: 3.551614281604998e-05\n",
      "Epoch 209: perda treino: 3.492563701001927e-05\n",
      "Epoch 210: perda treino: 3.434015889069997e-05\n",
      "Epoch 211: perda treino: 3.3761782106012106e-05\n",
      "Epoch 212: perda treino: 3.3188644010806456e-05\n",
      "Epoch 213: perda treino: 3.262574682594277e-05\n",
      "Epoch 214: perda treino: 3.207625195500441e-05\n",
      "Epoch 215: perda treino: 3.152381395921111e-05\n",
      "Epoch 216: perda treino: 3.0820254323771223e-05\n",
      "Epoch 217: perda treino: 3.00717383652227e-05\n",
      "Epoch 218: perda treino: 2.929945731011685e-05\n",
      "Epoch 219: perda treino: 2.851827593985945e-05\n",
      "Epoch 220: perda treino: 2.77374274446629e-05\n",
      "Epoch 221: perda treino: 2.6961337425746024e-05\n",
      "Epoch 222: perda treino: 2.6147739845328033e-05\n",
      "Epoch 223: perda treino: 2.5316112441942096e-05\n",
      "Epoch 224: perda treino: 2.435197529848665e-05\n",
      "Epoch 225: perda treino: 2.3364003936876543e-05\n",
      "Epoch 226: perda treino: 2.2374888430931605e-05\n",
      "Epoch 227: perda treino: 2.1400361220003106e-05\n",
      "Epoch 228: perda treino: 2.0445897462195717e-05\n",
      "Epoch 229: perda treino: 1.949059333128389e-05\n",
      "Epoch 230: perda treino: 1.8554557755123824e-05\n",
      "Epoch 231: perda treino: 1.7646314518060535e-05\n",
      "Epoch 232: perda treino: 1.677290492807515e-05\n",
      "Epoch 233: perda treino: 1.593893648532685e-05\n",
      "Epoch 234: perda treino: 1.5142521988309454e-05\n",
      "Epoch 235: perda treino: 1.4349229786603246e-05\n",
      "Epoch 236: perda treino: 1.3586984096036758e-05\n",
      "Epoch 237: perda treino: 1.2863156371167861e-05\n",
      "Epoch 238: perda treino: 1.2176411473774351e-05\n",
      "Epoch 239: perda treino: 1.1500235814310145e-05\n",
      "Epoch 240: perda treino: 1.0852648301806767e-05\n",
      "Epoch 241: perda treino: 1.0230000953015406e-05\n",
      "Epoch 242: perda treino: 9.641840733820572e-06\n",
      "Epoch 243: perda treino: 9.091977517527994e-06\n",
      "Epoch 244: perda treino: 8.58121711644344e-06\n",
      "Epoch 245: perda treino: 8.109093869279604e-06\n",
      "Epoch 246: perda treino: 7.674334483454004e-06\n",
      "Epoch 247: perda treino: 7.275565621966962e-06\n",
      "Epoch 248: perda treino: 6.910544016136555e-06\n",
      "Epoch 249: perda treino: 6.576603482244536e-06\n",
      "Epoch 250: perda treino: 6.2715294006920885e-06\n",
      "Epoch 251: perda treino: 5.99292525294004e-06\n",
      "Epoch 252: perda treino: 5.738864274462685e-06\n",
      "Epoch 253: perda treino: 5.503601187228924e-06\n",
      "Epoch 254: perda treino: 5.287913609208772e-06\n",
      "Epoch 255: perda treino: 5.079246875538956e-06\n",
      "Epoch 256: perda treino: 4.8727038119977806e-06\n",
      "Epoch 257: perda treino: 4.677307515521534e-06\n",
      "Epoch 258: perda treino: 4.494291715673171e-06\n",
      "Epoch 259: perda treino: 4.324316705606179e-06\n",
      "Epoch 260: perda treino: 4.166814051131951e-06\n",
      "Epoch 261: perda treino: 4.021880158688873e-06\n",
      "Epoch 262: perda treino: 3.888510946126189e-06\n",
      "Epoch 263: perda treino: 3.7651923321391223e-06\n",
      "Epoch 264: perda treino: 3.6519538753054803e-06\n",
      "Epoch 265: perda treino: 3.5478160498314537e-06\n",
      "Epoch 266: perda treino: 3.4453410080459435e-06\n",
      "Epoch 267: perda treino: 3.3481217087683035e-06\n",
      "Epoch 268: perda treino: 3.257234993725433e-06\n",
      "Epoch 269: perda treino: 3.1722179301141296e-06\n",
      "Epoch 270: perda treino: 3.0930120828998042e-06\n",
      "Epoch 271: perda treino: 3.0197106752893887e-06\n",
      "Epoch 272: perda treino: 2.9516825179598527e-06\n",
      "Epoch 273: perda treino: 2.8881368052680045e-06\n",
      "Epoch 274: perda treino: 2.82941255136393e-06\n",
      "Epoch 275: perda treino: 2.774341510303202e-06\n",
      "Epoch 276: perda treino: 2.7235223569732625e-06\n",
      "Epoch 277: perda treino: 2.6756040369946277e-06\n",
      "Epoch 278: perda treino: 2.6311788587918272e-06\n",
      "Epoch 279: perda treino: 2.5893477868521586e-06\n",
      "Epoch 280: perda treino: 2.5502681637590285e-06\n",
      "Epoch 281: perda treino: 2.5132851533271605e-06\n",
      "Epoch 282: perda treino: 2.4779528757790104e-06\n",
      "Epoch 283: perda treino: 2.4447610940114828e-06\n",
      "Epoch 284: perda treino: 2.4132407361321384e-06\n",
      "Epoch 285: perda treino: 2.3833267732698005e-06\n",
      "Epoch 286: perda treino: 2.354606294829864e-06\n",
      "Epoch 287: perda treino: 2.3276581941900076e-06\n",
      "Epoch 288: perda treino: 2.302022721778485e-06\n",
      "Epoch 289: perda treino: 2.2771107524022227e-06\n",
      "Epoch 290: perda treino: 2.253638513138867e-06\n",
      "Epoch 291: perda treino: 2.2312353848974453e-06\n",
      "Epoch 292: perda treino: 2.2094811811257387e-06\n",
      "Epoch 293: perda treino: 2.1884802663407754e-06\n",
      "Epoch 294: perda treino: 2.1686030322598526e-06\n",
      "Epoch 295: perda treino: 2.1492612631845986e-06\n",
      "Epoch 296: perda treino: 2.1306955204636324e-06\n",
      "Epoch 297: perda treino: 2.1127609670656966e-06\n",
      "Epoch 298: perda treino: 2.0951674741809256e-06\n",
      "Epoch 299: perda treino: 2.07794596462918e-06\n",
      "Epoch 300: perda treino: 2.0616619167412864e-06\n",
      "Epoch 301: perda treino: 2.0456370748433983e-06\n",
      "Epoch 302: perda treino: 2.0300813048379496e-06\n",
      "Epoch 303: perda treino: 2.0150105228822213e-06\n",
      "Epoch 304: perda treino: 2.0004731595690828e-06\n",
      "Epoch 305: perda treino: 1.9861138298438163e-06\n",
      "Epoch 306: perda treino: 1.972070094780065e-06\n",
      "Epoch 307: perda treino: 1.9585836525948253e-06\n",
      "Epoch 308: perda treino: 1.9454766970739e-06\n",
      "Epoch 309: perda treino: 1.9321289528306806e-06\n",
      "Epoch 310: perda treino: 1.9198134850739734e-06\n",
      "Epoch 311: perda treino: 1.907393880173913e-06\n",
      "Epoch 312: perda treino: 1.8952329128296697e-06\n",
      "Epoch 313: perda treino: 1.8831370880434406e-06\n",
      "Epoch 314: perda treino: 1.8715819578574155e-06\n",
      "Epoch 315: perda treino: 1.860261022557097e-06\n",
      "Epoch 316: perda treino: 1.8491095943318214e-06\n",
      "Epoch 317: perda treino: 1.837724880715541e-06\n",
      "Epoch 318: perda treino: 1.8270339978698757e-06\n",
      "Epoch 319: perda treino: 1.8160128547606291e-06\n",
      "Epoch 320: perda treino: 1.8055401369565516e-06\n",
      "Epoch 321: perda treino: 1.7952694406631053e-06\n",
      "Epoch 322: perda treino: 1.7853053577709943e-06\n",
      "Epoch 323: perda treino: 1.7750511460690177e-06\n",
      "Epoch 324: perda treino: 1.764950525284803e-06\n",
      "Epoch 325: perda treino: 1.755108087309054e-06\n",
      "Epoch 326: perda treino: 1.7456932255299762e-06\n",
      "Epoch 327: perda treino: 1.7360933952659252e-06\n",
      "Epoch 328: perda treino: 1.7269123873120407e-06\n",
      "Epoch 329: perda treino: 1.7170619912576512e-06\n",
      "Epoch 330: perda treino: 1.707445562715293e-06\n",
      "Epoch 331: perda treino: 1.6976755432551727e-06\n",
      "Epoch 332: perda treino: 1.6878976794032496e-06\n",
      "Epoch 333: perda treino: 1.678192347753793e-06\n",
      "Epoch 334: perda treino: 1.6685760328982724e-06\n",
      "Epoch 335: perda treino: 1.6590563518548151e-06\n",
      "Epoch 336: perda treino: 1.649198111408623e-06\n",
      "Epoch 337: perda treino: 1.6394690192100825e-06\n",
      "Epoch 338: perda treino: 1.6304982182191452e-06\n",
      "Epoch 339: perda treino: 1.6214225979638286e-06\n",
      "Epoch 340: perda treino: 1.6119362271638238e-06\n",
      "Epoch 341: perda treino: 1.6031025324991788e-06\n",
      "Epoch 342: perda treino: 1.593898332430399e-06\n",
      "Epoch 343: perda treino: 1.585065433573618e-06\n",
      "Epoch 344: perda treino: 1.5761437452965765e-06\n",
      "Epoch 345: perda treino: 1.567843241900846e-06\n",
      "Epoch 346: perda treino: 1.5594299611620954e-06\n",
      "Epoch 347: perda treino: 1.551153900436475e-06\n",
      "Epoch 348: perda treino: 1.5429342283823644e-06\n",
      "Epoch 349: perda treino: 1.5348034594353521e-06\n",
      "Epoch 350: perda treino: 1.5265842421285925e-06\n",
      "Epoch 351: perda treino: 1.518550334367319e-06\n",
      "Epoch 352: perda treino: 1.510887841504882e-06\n",
      "Epoch 353: perda treino: 1.5033541558295838e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354: perda treino: 1.4955062397348229e-06\n",
      "Epoch 355: perda treino: 1.4878276033414295e-06\n",
      "Epoch 356: perda treino: 1.4802782288825256e-06\n",
      "Epoch 357: perda treino: 1.4731321016370202e-06\n",
      "Epoch 358: perda treino: 1.4659776752523612e-06\n",
      "Epoch 359: perda treino: 1.4588803196602385e-06\n",
      "Epoch 360: perda treino: 1.451500224902702e-06\n",
      "Epoch 361: perda treino: 1.444572035325109e-06\n",
      "Epoch 362: perda treino: 1.437660216652148e-06\n",
      "Epoch 363: perda treino: 1.4306593811852508e-06\n",
      "Epoch 364: perda treino: 1.4239249139791355e-06\n",
      "Epoch 365: perda treino: 1.4172067039908143e-06\n",
      "Epoch 366: perda treino: 1.4103673038334819e-06\n",
      "Epoch 367: perda treino: 1.4024959682501503e-06\n",
      "Epoch 368: perda treino: 1.3921813888373435e-06\n",
      "Epoch 369: perda treino: 1.3809152505928068e-06\n",
      "Epoch 370: perda treino: 1.3705681567444117e-06\n",
      "Epoch 371: perda treino: 1.3585521401182632e-06\n",
      "Epoch 372: perda treino: 1.34410083774128e-06\n",
      "Epoch 373: perda treino: 1.3252710004962864e-06\n",
      "Epoch 374: perda treino: 1.3014175692660501e-06\n",
      "Epoch 375: perda treino: 1.2710004284599563e-06\n",
      "Epoch 376: perda treino: 1.2340034345470485e-06\n",
      "Epoch 377: perda treino: 1.191055389426765e-06\n",
      "Epoch 378: perda treino: 1.1432373412390007e-06\n",
      "Epoch 379: perda treino: 1.090831233341305e-06\n",
      "Epoch 380: perda treino: 1.032611180562526e-06\n",
      "Epoch 381: perda treino: 9.70230530583649e-07\n",
      "Epoch 382: perda treino: 9.071085287359892e-07\n",
      "Epoch 383: perda treino: 8.430753268839908e-07\n",
      "Epoch 384: perda treino: 7.779618726999615e-07\n",
      "Epoch 385: perda treino: 7.138564797060098e-07\n",
      "Epoch 386: perda treino: 6.512670438496571e-07\n",
      "Epoch 387: perda treino: 5.930965016887058e-07\n",
      "Epoch 388: perda treino: 5.37925700427877e-07\n",
      "Epoch 389: perda treino: 4.877301762462594e-07\n",
      "Epoch 390: perda treino: 4.419212018547114e-07\n",
      "Epoch 391: perda treino: 4.004824631920201e-07\n",
      "Epoch 392: perda treino: 3.6376866319187684e-07\n",
      "Epoch 393: perda treino: 3.3136049637505494e-07\n",
      "Epoch 394: perda treino: 3.0254022931330837e-07\n",
      "Epoch 395: perda treino: 2.7667090307659237e-07\n",
      "Epoch 396: perda treino: 2.5335748432553373e-07\n",
      "Epoch 397: perda treino: 2.3321281616972556e-07\n",
      "Epoch 398: perda treino: 2.1502755487290415e-07\n",
      "Epoch 399: perda treino: 1.9860011946093437e-07\n",
      "Epoch 400: perda treino: 1.8297909321063344e-07\n",
      "Epoch 401: perda treino: 1.6961591597919323e-07\n",
      "Epoch 402: perda treino: 1.568898682080544e-07\n",
      "Epoch 403: perda treino: 1.4854347796244838e-07\n",
      "Epoch 404: perda treino: 1.4128598024854e-07\n",
      "Epoch 405: perda treino: 1.34705828713777e-07\n",
      "Epoch 406: perda treino: 1.2867404564076423e-07\n",
      "Epoch 407: perda treino: 1.23408270269465e-07\n",
      "Epoch 408: perda treino: 1.1868277027815566e-07\n",
      "Epoch 409: perda treino: 1.1451367498693799e-07\n",
      "Epoch 410: perda treino: 1.1086871154475375e-07\n",
      "Epoch 411: perda treino: 1.0742535039298673e-07\n",
      "Epoch 412: perda treino: 1.0410295203655551e-07\n",
      "Epoch 413: perda treino: 1.0107083880939172e-07\n",
      "Epoch 414: perda treino: 9.83048380476248e-08\n",
      "Epoch 415: perda treino: 9.590976191020673e-08\n",
      "Epoch 416: perda treino: 9.350663532359249e-08\n",
      "Epoch 417: perda treino: 9.136155654232425e-08\n",
      "Epoch 418: perda treino: 8.939387186046588e-08\n",
      "Epoch 419: perda treino: 8.749070445901452e-08\n",
      "Epoch 420: perda treino: 8.574880183687128e-08\n",
      "Epoch 421: perda treino: 8.414399133016559e-08\n",
      "Epoch 422: perda treino: 8.274077600844976e-08\n",
      "Epoch 423: perda treino: 8.13617475614592e-08\n",
      "Epoch 424: perda treino: 7.979727456586261e-08\n",
      "Epoch 425: perda treino: 7.848277761013378e-08\n",
      "Epoch 426: perda treino: 7.724085548943549e-08\n",
      "Epoch 427: perda treino: 7.632954179825902e-08\n",
      "Epoch 428: perda treino: 7.505536814278457e-08\n",
      "Epoch 429: perda treino: 7.386989864244242e-08\n",
      "Epoch 430: perda treino: 7.29747142713677e-08\n",
      "Epoch 431: perda treino: 7.197471774134101e-08\n",
      "Epoch 432: perda treino: 7.10634111555919e-08\n",
      "Epoch 433: perda treino: 7.003922775083993e-08\n",
      "Epoch 434: perda treino: 6.924082640580309e-08\n",
      "Epoch 435: perda treino: 6.846661904091889e-08\n",
      "Epoch 436: perda treino: 6.762790150105502e-08\n",
      "Epoch 437: perda treino: 6.696658516602838e-08\n",
      "Epoch 438: perda treino: 6.617624848104242e-08\n",
      "Epoch 439: perda treino: 6.553106857154489e-08\n",
      "Epoch 440: perda treino: 6.485363002184386e-08\n",
      "Epoch 441: perda treino: 6.412781772269227e-08\n",
      "Epoch 442: perda treino: 6.347458025857122e-08\n",
      "Epoch 443: perda treino: 6.289391052405335e-08\n",
      "Epoch 444: perda treino: 6.23938802846169e-08\n",
      "Epoch 445: perda treino: 6.177290146069936e-08\n",
      "Epoch 446: perda treino: 6.124061968648675e-08\n",
      "Epoch 447: perda treino: 6.069220859217239e-08\n",
      "Epoch 448: perda treino: 6.022443699293945e-08\n",
      "Epoch 449: perda treino: 5.9587343059774867e-08\n",
      "Epoch 450: perda treino: 5.910344924586752e-08\n",
      "Epoch 451: perda treino: 5.852279016949069e-08\n",
      "Epoch 452: perda treino: 5.814373338353107e-08\n",
      "Epoch 453: perda treino: 5.767596888972548e-08\n",
      "Epoch 454: perda treino: 5.72324019287862e-08\n",
      "Epoch 455: perda treino: 5.6821086502623075e-08\n",
      "Epoch 456: perda treino: 5.635333266695852e-08\n",
      "Epoch 457: perda treino: 5.589363993863117e-08\n",
      "Epoch 458: perda treino: 5.544201897578205e-08\n",
      "Epoch 459: perda treino: 5.50871490645477e-08\n",
      "Epoch 460: perda treino: 5.469196651120001e-08\n",
      "Epoch 461: perda treino: 5.426453597578984e-08\n",
      "Epoch 462: perda treino: 5.384517010043055e-08\n",
      "Epoch 463: perda treino: 5.3441933545173015e-08\n",
      "Epoch 464: perda treino: 5.307900963202883e-08\n",
      "Epoch 465: perda treino: 5.264352154199514e-08\n",
      "Epoch 466: perda treino: 5.2240284986737606e-08\n",
      "Epoch 467: perda treino: 5.18128615567548e-08\n",
      "Epoch 468: perda treino: 5.1498322051202194e-08\n",
      "Epoch 469: perda treino: 5.1159599223638e-08\n",
      "Epoch 470: perda treino: 5.0675733831440084e-08\n",
      "Epoch 471: perda treino: 5.032088523648781e-08\n",
      "Epoch 472: perda treino: 5.00305468165152e-08\n",
      "Epoch 473: perda treino: 4.9707953309052755e-08\n",
      "Epoch 474: perda treino: 4.935310471410048e-08\n",
      "Epoch 475: perda treino: 4.894181060421943e-08\n",
      "Epoch 476: perda treino: 4.862728530952154e-08\n",
      "Epoch 477: perda treino: 4.821599475235416e-08\n",
      "Epoch 478: perda treino: 4.7901473010369955e-08\n",
      "Epoch 479: perda treino: 4.762726035778542e-08\n",
      "Epoch 480: perda treino: 4.735305481062824e-08\n",
      "Epoch 481: perda treino: 4.7022403748542274e-08\n",
      "Epoch 482: perda treino: 4.676432396877317e-08\n",
      "Epoch 483: perda treino: 4.644174111945176e-08\n",
      "Epoch 484: perda treino: 4.616753912500826e-08\n",
      "Epoch 485: perda treino: 4.586107849036125e-08\n",
      "Epoch 486: perda treino: 4.558688004863143e-08\n",
      "Epoch 487: perda treino: 4.524816432649459e-08\n",
      "Epoch 488: perda treino: 4.4949771904612135e-08\n",
      "Epoch 489: perda treino: 4.465138303544336e-08\n",
      "Epoch 490: perda treino: 4.4417500788540565e-08\n",
      "Epoch 491: perda treino: 4.415942811419882e-08\n",
      "Epoch 492: perda treino: 4.390135543985707e-08\n",
      "Epoch 493: perda treino: 4.36513474255662e-08\n",
      "Epoch 494: perda treino: 4.3352962109111104e-08\n",
      "Epoch 495: perda treino: 4.305457323994233e-08\n",
      "Epoch 496: perda treino: 4.277231013816163e-08\n",
      "Epoch 497: perda treino: 4.2498115249145485e-08\n",
      "Epoch 498: perda treino: 4.2352954920943375e-08\n",
      "Epoch 499: perda treino: 4.198198055860303e-08\n",
      "Epoch 500: perda treino: 4.1772292291852864e-08\n",
      "Epoch 501: perda treino: 4.153035604304023e-08\n",
      "Epoch 502: perda treino: 4.131260311623919e-08\n",
      "Epoch 503: perda treino: 4.1102918402202704e-08\n",
      "Epoch 504: perda treino: 4.089323368816622e-08\n",
      "Epoch 505: perda treino: 4.069967474151781e-08\n",
      "Epoch 506: perda treino: 4.0457734939991497e-08\n",
      "Epoch 507: perda treino: 4.0199672923790786e-08\n",
      "Epoch 508: perda treino: 4.001418574262061e-08\n",
      "Epoch 509: perda treino: 3.9820623243258524e-08\n",
      "Epoch 510: perda treino: 3.962707140203747e-08\n",
      "Epoch 511: perda treino: 3.9457706435541695e-08\n",
      "Epoch 512: perda treino: 3.928028036170872e-08\n",
      "Epoch 513: perda treino: 3.9070595647672235e-08\n",
      "Epoch 514: perda treino: 3.8836727611624156e-08\n",
      "Epoch 515: perda treino: 3.861898889567783e-08\n",
      "Epoch 516: perda treino: 3.8409304181641346e-08\n",
      "Epoch 517: perda treino: 3.820768768036942e-08\n",
      "Epoch 518: perda treino: 3.800607473181117e-08\n",
      "Epoch 519: perda treino: 3.7820587550640994e-08\n",
      "Epoch 520: perda treino: 3.759478417464379e-08\n",
      "Epoch 521: perda treino: 3.736091613859571e-08\n",
      "Epoch 522: perda treino: 3.716736785008834e-08\n",
      "Epoch 523: perda treino: 3.7014132203694317e-08\n",
      "Epoch 524: perda treino: 3.690122341026836e-08\n",
      "Epoch 525: perda treino: 3.673991955110978e-08\n",
      "Epoch 526: perda treino: 3.656249702999048e-08\n",
      "Epoch 527: perda treino: 3.636894874148311e-08\n",
      "Epoch 528: perda treino: 3.616733579292486e-08\n",
      "Epoch 529: perda treino: 3.600604259190732e-08\n",
      "Epoch 530: perda treino: 3.582055896345082e-08\n",
      "Epoch 531: perda treino: 3.5667330422484156e-08\n",
      "Epoch 532: perda treino: 3.550604077418029e-08\n",
      "Epoch 533: perda treino: 3.534474402044907e-08\n",
      "Epoch 534: perda treino: 3.516732505204345e-08\n",
      "Epoch 535: perda treino: 3.4957650996148004e-08\n",
      "Epoch 536: perda treino: 3.480442245518134e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 537: perda treino: 3.465119746692835e-08\n",
      "Epoch 538: perda treino: 3.451409469334976e-08\n",
      "Epoch 539: perda treino: 3.4336675724944143e-08\n",
      "Epoch 540: perda treino: 3.41673214165894e-08\n",
      "Epoch 541: perda treino: 3.401409287562274e-08\n",
      "Epoch 542: perda treino: 3.386892899470695e-08\n",
      "Epoch 543: perda treino: 3.370764289911676e-08\n",
      "Epoch 544: perda treino: 3.357054367825185e-08\n",
      "Epoch 545: perda treino: 3.3425379797336063e-08\n",
      "Epoch 546: perda treino: 3.329634168380835e-08\n",
      "Epoch 547: perda treino: 3.3135052035504486e-08\n",
      "Epoch 548: perda treino: 3.297376949262798e-08\n",
      "Epoch 549: perda treino: 3.282860561171219e-08\n",
      "Epoch 550: perda treino: 3.2643125535969375e-08\n",
      "Epoch 551: perda treino: 3.2530216742543416e-08\n",
      "Epoch 552: perda treino: 3.2360865986902354e-08\n",
      "Epoch 553: perda treino: 3.222377031875112e-08\n",
      "Epoch 554: perda treino: 3.2102796865274286e-08\n",
      "Epoch 555: perda treino: 3.198990228270304e-08\n",
      "Epoch 556: perda treino: 3.177216356675672e-08\n",
      "Epoch 557: perda treino: 3.165925477333076e-08\n",
      "Epoch 558: perda treino: 3.151409089241497e-08\n",
      "Epoch 559: perda treino: 3.1385059884314614e-08\n",
      "Epoch 560: perda treino: 3.1207648021336354e-08\n",
      "Epoch 561: perda treino: 3.1094742780624074e-08\n",
      "Epoch 562: perda treino: 3.0981837539911794e-08\n",
      "Epoch 563: perda treino: 3.084474187176056e-08\n",
      "Epoch 564: perda treino: 3.069958154355845e-08\n",
      "Epoch 565: perda treino: 3.0578615195508974e-08\n",
      "Epoch 566: perda treino: 3.037700935237808e-08\n",
      "Epoch 567: perda treino: 3.027216877171668e-08\n",
      "Epoch 568: perda treino: 3.019151861849423e-08\n",
      "Epoch 569: perda treino: 3.0086678037832826e-08\n",
      "Epoch 570: perda treino: 2.995765058244615e-08\n",
      "Epoch 571: perda treino: 2.985280644907107e-08\n",
      "Epoch 572: perda treino: 2.9739906537429306e-08\n",
      "Epoch 573: perda treino: 2.9610871976615272e-08\n",
      "Epoch 574: perda treino: 2.9522162492412463e-08\n",
      "Epoch 575: perda treino: 2.9401194368006145e-08\n",
      "Epoch 576: perda treino: 2.9296353787344742e-08\n",
      "Epoch 577: perda treino: 2.9167326331958066e-08\n",
      "Epoch 578: perda treino: 2.9054424643959464e-08\n",
      "Epoch 579: perda treino: 2.8901201432063317e-08\n",
      "Epoch 580: perda treino: 2.8780236860370678e-08\n",
      "Epoch 581: perda treino: 2.869152559981103e-08\n",
      "Epoch 582: perda treino: 2.8586688571863306e-08\n",
      "Epoch 583: perda treino: 2.8449594680068913e-08\n",
      "Epoch 584: perda treino: 2.8352820535815226e-08\n",
      "Epoch 585: perda treino: 2.8239918847816625e-08\n",
      "Epoch 586: perda treino: 2.8135080043512062e-08\n",
      "Epoch 587: perda treino: 2.8030244791921177e-08\n",
      "Epoch 588: perda treino: 2.7933467094953812e-08\n",
      "Epoch 589: perda treino: 2.7868955143617313e-08\n",
      "Epoch 590: perda treino: 2.7723793039058364e-08\n",
      "Epoch 591: perda treino: 2.7643144662192753e-08\n",
      "Epoch 592: perda treino: 2.7481863895673087e-08\n",
      "Epoch 593: perda treino: 2.7377026867725363e-08\n",
      "Epoch 594: perda treino: 2.7280252723471676e-08\n",
      "Epoch 595: perda treino: 2.7199607899319744e-08\n",
      "Epoch 596: perda treino: 2.7102833755066058e-08\n",
      "Epoch 597: perda treino: 2.701412427086325e-08\n",
      "Epoch 598: perda treino: 2.6885096815476572e-08\n",
      "Epoch 599: perda treino: 2.678025978752885e-08\n",
      "Epoch 600: perda treino: 2.6683485643275162e-08\n",
      "Epoch 601: perda treino: 2.6610905479174107e-08\n",
      "Epoch 602: perda treino: 2.6489942683838308e-08\n",
      "Epoch 603: perda treino: 2.6377040995839707e-08\n",
      "Epoch 604: perda treino: 2.6288333287993737e-08\n",
      "Epoch 605: perda treino: 2.6199625580147767e-08\n",
      "Epoch 606: perda treino: 2.6110917872301798e-08\n",
      "Epoch 607: perda treino: 2.6006079067997234e-08\n",
      "Epoch 608: perda treino: 2.5909306700100387e-08\n",
      "Epoch 609: perda treino: 2.5828663652305295e-08\n",
      "Epoch 610: perda treino: 2.5731891284408448e-08\n",
      "Epoch 611: perda treino: 2.563512069286844e-08\n",
      "Epoch 612: perda treino: 2.5562538752410546e-08\n",
      "Epoch 613: perda treino: 2.546576460815686e-08\n",
      "Epoch 614: perda treino: 2.537705867666773e-08\n",
      "Epoch 615: perda treino: 2.528835096882176e-08\n",
      "Epoch 616: perda treino: 2.5175451057179998e-08\n",
      "Epoch 617: perda treino: 2.5110932000416142e-08\n",
      "Epoch 618: perda treino: 2.503029072897789e-08\n",
      "Epoch 619: perda treino: 2.4917390817336127e-08\n",
      "Epoch 620: perda treino: 2.482062022579612e-08\n",
      "Epoch 621: perda treino: 2.4756102945389102e-08\n",
      "Epoch 622: perda treino: 2.4667395237543133e-08\n",
      "Epoch 623: perda treino: 2.4635138373696464e-08\n",
      "Epoch 624: perda treino: 2.4522234909341023e-08\n",
      "Epoch 625: perda treino: 2.441739965775014e-08\n",
      "Epoch 626: perda treino: 2.428837753143398e-08\n",
      "Epoch 627: perda treino: 2.4191606939893973e-08\n",
      "Epoch 628: perda treino: 2.411096211574204e-08\n",
      "Epoch 629: perda treino: 2.3998067533170797e-08\n",
      "Epoch 630: perda treino: 2.3917422709018865e-08\n",
      "Epoch 631: perda treino: 2.3836779661223773e-08\n",
      "Epoch 632: perda treino: 2.3748073729734642e-08\n",
      "Epoch 633: perda treino: 2.3683558225684465e-08\n",
      "Epoch 634: perda treino: 2.357872475045042e-08\n",
      "Epoch 635: perda treino: 2.3506146362706204e-08\n",
      "Epoch 636: perda treino: 2.340131288747216e-08\n",
      "Epoch 637: perda treino: 2.331260695598303e-08\n",
      "Epoch 638: perda treino: 2.324808967557601e-08\n",
      "Epoch 639: perda treino: 2.315938729680056e-08\n",
      "Epoch 640: perda treino: 2.307067958895459e-08\n",
      "Epoch 641: perda treino: 2.2998101201210375e-08\n",
      "Epoch 642: perda treino: 2.2917458153415282e-08\n",
      "Epoch 643: perda treino: 2.282875399828299e-08\n",
      "Epoch 644: perda treino: 2.274004629043702e-08\n",
      "Epoch 645: perda treino: 2.265134213530473e-08\n",
      "Epoch 646: perda treino: 2.2586826631254553e-08\n",
      "Epoch 647: perda treino: 2.2514248243510337e-08\n",
      "Epoch 648: perda treino: 2.2433608748428924e-08\n",
      "Epoch 649: perda treino: 2.2344901040582954e-08\n",
      "Epoch 650: perda treino: 2.2223941797960833e-08\n",
      "Epoch 651: perda treino: 2.2151365186573457e-08\n",
      "Epoch 652: perda treino: 2.205459459503345e-08\n",
      "Epoch 653: perda treino: 2.199814552739099e-08\n",
      "Epoch 654: perda treino: 2.193363002334081e-08\n",
      "Epoch 655: perda treino: 2.1869114519290633e-08\n",
      "Epoch 656: perda treino: 2.178847324785238e-08\n",
      "Epoch 657: perda treino: 2.1740088840260796e-08\n",
      "Epoch 658: perda treino: 2.1643320025077628e-08\n",
      "Epoch 659: perda treino: 2.154654943353762e-08\n",
      "Epoch 660: perda treino: 2.1465909938456207e-08\n",
      "Epoch 661: perda treino: 2.140139621076287e-08\n",
      "Epoch 662: perda treino: 2.133688070671269e-08\n",
      "Epoch 663: perda treino: 2.1272368755376192e-08\n",
      "Epoch 664: perda treino: 2.1207853251326014e-08\n",
      "Epoch 665: perda treino: 2.11352748635818e-08\n",
      "Epoch 666: perda treino: 2.1078825795939338e-08\n",
      "Epoch 667: perda treino: 2.1030439611990914e-08\n",
      "Epoch 668: perda treino: 2.0973988767991614e-08\n",
      "Epoch 669: perda treino: 2.0885284612859323e-08\n",
      "Epoch 670: perda treino: 2.0820770885165985e-08\n",
      "Epoch 671: perda treino: 2.0756255381115807e-08\n",
      "Epoch 672: perda treino: 2.0691743429779308e-08\n",
      "Epoch 673: perda treino: 2.0619166818391932e-08\n",
      "Epoch 674: perda treino: 2.057078063444351e-08\n",
      "Epoch 675: perda treino: 2.0514329790444208e-08\n",
      "Epoch 676: perda treino: 2.0409498091567002e-08\n",
      "Epoch 677: perda treino: 2.032885859648559e-08\n",
      "Epoch 678: perda treino: 2.0280472412537165e-08\n",
      "Epoch 679: perda treino: 2.023208622858874e-08\n",
      "Epoch 680: perda treino: 2.0167572500895403e-08\n",
      "Epoch 681: perda treino: 2.0111123433252942e-08\n",
      "Epoch 682: perda treino: 2.0046609705559604e-08\n",
      "Epoch 683: perda treino: 1.9949842666733275e-08\n",
      "Epoch 684: perda treino: 1.9885330715396776e-08\n",
      "Epoch 685: perda treino: 1.9836944531448353e-08\n",
      "Epoch 686: perda treino: 1.978855657114309e-08\n",
      "Epoch 687: perda treino: 1.9748236823602383e-08\n",
      "Epoch 688: perda treino: 1.9691785979603083e-08\n",
      "Epoch 689: perda treino: 1.963533691196062e-08\n",
      "Epoch 690: perda treino: 1.9562760300573245e-08\n",
      "Epoch 691: perda treino: 1.9498246572879907e-08\n",
      "Epoch 692: perda treino: 1.94579268253392e-08\n",
      "Epoch 693: perda treino: 1.940147420498306e-08\n",
      "Epoch 694: perda treino: 1.93369640300034e-08\n",
      "Epoch 695: perda treino: 1.9288579622411817e-08\n",
      "Epoch 696: perda treino: 1.922406589471848e-08\n",
      "Epoch 697: perda treino: 1.9175679710770055e-08\n",
      "Epoch 698: perda treino: 1.9078914448300566e-08\n",
      "Epoch 699: perda treino: 1.903053181706582e-08\n",
      "Epoch 700: perda treino: 1.898214208040372e-08\n",
      "Epoch 701: perda treino: 1.891763190542406e-08\n",
      "Epoch 702: perda treino: 1.8845055294036683e-08\n",
      "Epoch 703: perda treino: 1.87966708864451e-08\n",
      "Epoch 704: perda treino: 1.8724094275057723e-08\n",
      "Epoch 705: perda treino: 1.867570986746614e-08\n",
      "Epoch 706: perda treino: 1.8627325459874555e-08\n",
      "Epoch 707: perda treino: 1.8562811732181217e-08\n",
      "Epoch 708: perda treino: 1.8514425548232794e-08\n",
      "Epoch 709: perda treino: 1.846604114064121e-08\n",
      "Epoch 710: perda treino: 1.8417656733049625e-08\n",
      "Epoch 711: perda treino: 1.840152741294787e-08\n",
      "Epoch 712: perda treino: 1.8361204112693486e-08\n",
      "Epoch 713: perda treino: 1.8304755045051024e-08\n",
      "Epoch 714: perda treino: 1.8240243093714525e-08\n",
      "Epoch 715: perda treino: 1.816766648232715e-08\n",
      "Epoch 716: perda treino: 1.8151535385868556e-08\n",
      "Epoch 717: perda treino: 1.811121563832785e-08\n",
      "Epoch 718: perda treino: 1.807895699812434e-08\n",
      "Epoch 719: perda treino: 1.8030570814175917e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720: perda treino: 1.7982186406584333e-08\n",
      "Epoch 721: perda treino: 1.793380199899275e-08\n",
      "Epoch 722: perda treino: 1.790154513514608e-08\n",
      "Epoch 723: perda treino: 1.7788650552574836e-08\n",
      "Epoch 724: perda treino: 1.7756395465085006e-08\n",
      "Epoch 725: perda treino: 1.7699946397442545e-08\n",
      "Epoch 726: perda treino: 1.7667687757239037e-08\n",
      "Epoch 727: perda treino: 1.7603177582259377e-08\n",
      "Epoch 728: perda treino: 1.7554793174667793e-08\n",
      "Epoch 729: perda treino: 1.749834765973901e-08\n",
      "Epoch 730: perda treino: 1.737738841711689e-08\n",
      "Epoch 731: perda treino: 1.7329005785882146e-08\n",
      "Epoch 732: perda treino: 1.728062137829056e-08\n",
      "Epoch 733: perda treino: 1.7199981883209148e-08\n",
      "Epoch 734: perda treino: 1.7167726795719318e-08\n",
      "Epoch 735: perda treino: 1.7119342388127734e-08\n",
      "Epoch 736: perda treino: 1.7054828660434396e-08\n",
      "Epoch 737: perda treino: 1.700644602919965e-08\n",
      "Epoch 738: perda treino: 1.6974189165352982e-08\n",
      "Epoch 739: perda treino: 1.692580298140456e-08\n",
      "Epoch 740: perda treino: 1.685322992273086e-08\n",
      "Epoch 741: perda treino: 1.6804845515139277e-08\n",
      "Epoch 742: perda treino: 1.6772588651292608e-08\n",
      "Epoch 743: perda treino: 1.670807669995611e-08\n",
      "Epoch 744: perda treino: 1.664356652497645e-08\n",
      "Epoch 745: perda treino: 1.6595182117384866e-08\n",
      "Epoch 746: perda treino: 1.6562925253538197e-08\n",
      "Epoch 747: perda treino: 1.6498413302201698e-08\n",
      "Epoch 748: perda treino: 1.646615643835503e-08\n",
      "Epoch 749: perda treino: 1.643389957450836e-08\n",
      "Epoch 750: perda treino: 1.6417768478049766e-08\n",
      "Epoch 751: perda treino: 1.6385513390559936e-08\n",
      "Epoch 752: perda treino: 1.6361317634050465e-08\n",
      "Epoch 753: perda treino: 1.631293322645888e-08\n",
      "Epoch 754: perda treino: 1.6264550595224136e-08\n",
      "Epoch 755: perda treino: 1.6232293731377467e-08\n",
      "Epoch 756: perda treino: 1.6200036867530798e-08\n",
      "Epoch 757: perda treino: 1.616778000368413e-08\n",
      "Epoch 758: perda treino: 1.6119395596092545e-08\n",
      "Epoch 759: perda treino: 1.6079075848551838e-08\n",
      "Epoch 760: perda treino: 1.604681898470517e-08\n",
      "Epoch 761: perda treino: 1.5998434577113585e-08\n",
      "Epoch 762: perda treino: 1.5933924402133925e-08\n",
      "Epoch 763: perda treino: 1.5917793305675332e-08\n",
      "Epoch 764: perda treino: 1.589360287823638e-08\n",
      "Epoch 765: perda treino: 1.582908915054304e-08\n",
      "Epoch 766: perda treino: 1.5788769403002334e-08\n",
      "Epoch 767: perda treino: 1.5724259228022675e-08\n",
      "Epoch 768: perda treino: 1.5692004140532845e-08\n",
      "Epoch 769: perda treino: 1.564361973294126e-08\n",
      "Epoch 770: perda treino: 1.561136286909459e-08\n",
      "Epoch 771: perda treino: 1.5579106005247922e-08\n",
      "Epoch 772: perda treino: 1.553072159765634e-08\n",
      "Epoch 773: perda treino: 1.5482338966421594e-08\n",
      "Epoch 774: perda treino: 1.5450082102574925e-08\n",
      "Epoch 775: perda treino: 1.5385571927595265e-08\n",
      "Epoch 776: perda treino: 1.5353315063748596e-08\n",
      "Epoch 777: perda treino: 1.530493243251385e-08\n",
      "Epoch 778: perda treino: 1.5272675568667182e-08\n",
      "Epoch 779: perda treino: 1.5256548024922267e-08\n",
      "Epoch 780: perda treino: 1.521622650102472e-08\n",
      "Epoch 781: perda treino: 1.518397141353489e-08\n",
      "Epoch 782: perda treino: 1.512752412224927e-08\n",
      "Epoch 783: perda treino: 1.506301394726961e-08\n",
      "Epoch 784: perda treino: 1.4990440888595913e-08\n",
      "Epoch 785: perda treino: 1.4958184024749244e-08\n",
      "Epoch 786: perda treino: 1.4925927160902575e-08\n",
      "Epoch 787: perda treino: 1.4885607413361868e-08\n",
      "Epoch 788: perda treino: 1.487754186513257e-08\n",
      "Epoch 789: perda treino: 1.4845285001285902e-08\n",
      "Epoch 790: perda treino: 1.4804965253745195e-08\n",
      "Epoch 791: perda treino: 1.4772709278076945e-08\n",
      "Epoch 792: perda treino: 1.4756579069796771e-08\n",
      "Epoch 793: perda treino: 1.4724322205950102e-08\n",
      "Epoch 794: perda treino: 1.4708194662205187e-08\n",
      "Epoch 795: perda treino: 1.4675937798358518e-08\n",
      "Epoch 796: perda treino: 1.4635618050817811e-08\n",
      "Epoch 797: perda treino: 1.4587234531404647e-08\n",
      "Epoch 798: perda treino: 1.4554978555736398e-08\n",
      "Epoch 799: perda treino: 1.4530786351940606e-08\n",
      "Epoch 800: perda treino: 1.4490466604399899e-08\n",
      "Epoch 801: perda treino: 1.4450146856859192e-08\n",
      "Epoch 802: perda treino: 1.4417890881190942e-08\n",
      "Epoch 803: perda treino: 1.4401761561089188e-08\n",
      "Epoch 804: perda treino: 1.4353378929854443e-08\n",
      "Epoch 805: perda treino: 1.4321122066007774e-08\n",
      "Epoch 806: perda treino: 1.4280802318467067e-08\n",
      "Epoch 807: perda treino: 1.4256611002849695e-08\n",
      "Epoch 808: perda treino: 1.4224354139003026e-08\n",
      "Epoch 809: perda treino: 1.4175971507768281e-08\n",
      "Epoch 810: perda treino: 1.4143714643921612e-08\n",
      "Epoch 811: perda treino: 1.4127587100176697e-08\n",
      "Epoch 812: perda treino: 1.4079203580763533e-08\n",
      "Epoch 813: perda treino: 1.4046946716916864e-08\n",
      "Epoch 814: perda treino: 1.4030819173171949e-08\n",
      "Epoch 815: perda treino: 1.3974371881886327e-08\n",
      "Epoch 816: perda treino: 1.3942115906218078e-08\n",
      "Epoch 817: perda treino: 1.3917924590600705e-08\n",
      "Epoch 818: perda treino: 1.3869541071187541e-08\n",
      "Epoch 819: perda treino: 1.3837285095519292e-08\n",
      "Epoch 820: perda treino: 1.381309377990192e-08\n",
      "Epoch 821: perda treino: 1.378083691605525e-08\n",
      "Epoch 822: perda treino: 1.3732453396642086e-08\n",
      "Epoch 823: perda treino: 1.3716325852897171e-08\n",
      "Epoch 824: perda treino: 1.3684068989050502e-08\n",
      "Epoch 825: perda treino: 1.3667941445305587e-08\n",
      "Epoch 826: perda treino: 1.3635684581458918e-08\n",
      "Epoch 827: perda treino: 1.3603428605790668e-08\n",
      "Epoch 828: perda treino: 1.3587301062045753e-08\n",
      "Epoch 829: perda treino: 1.3555044198199084e-08\n",
      "Epoch 830: perda treino: 1.3522789110709255e-08\n",
      "Epoch 831: perda treino: 1.347440647947451e-08\n",
      "Epoch 832: perda treino: 1.3450215163857138e-08\n",
      "Epoch 833: perda treino: 1.3393767872571516e-08\n",
      "Epoch 834: perda treino: 1.3345385241336771e-08\n",
      "Epoch 835: perda treino: 1.3329256809413437e-08\n",
      "Epoch 836: perda treino: 1.3297000833745187e-08\n",
      "Epoch 837: perda treino: 1.3264745746255358e-08\n",
      "Epoch 838: perda treino: 1.3232489770587108e-08\n",
      "Epoch 839: perda treino: 1.3200234683097278e-08\n",
      "Epoch 840: perda treino: 1.3167978707429029e-08\n",
      "Epoch 841: perda treino: 1.3151850275505694e-08\n",
      "Epoch 842: perda treino: 1.3119594299837445e-08\n",
      "Epoch 843: perda treino: 1.3079276328653577e-08\n",
      "Epoch 844: perda treino: 1.3055085013036205e-08\n",
      "Epoch 845: perda treino: 1.3030891921061993e-08\n",
      "Epoch 846: perda treino: 1.2998635057215324e-08\n",
      "Epoch 847: perda treino: 1.298250751347041e-08\n",
      "Epoch 848: perda treino: 1.2958314421496198e-08\n",
      "Epoch 849: perda treino: 1.2942185989572863e-08\n",
      "Epoch 850: perda treino: 1.2893803358338118e-08\n",
      "Epoch 851: perda treino: 1.2853485387154251e-08\n",
      "Epoch 852: perda treino: 1.2805102755919506e-08\n",
      "Epoch 853: perda treino: 1.2788974323996172e-08\n",
      "Epoch 854: perda treino: 1.2748654576455465e-08\n",
      "Epoch 855: perda treino: 1.273252614453213e-08\n",
      "Epoch 856: perda treino: 1.2716398600787215e-08\n",
      "Epoch 857: perda treino: 1.2684142625118966e-08\n",
      "Epoch 858: perda treino: 1.2668014193195631e-08\n",
      "Epoch 859: perda treino: 1.2603504906394392e-08\n",
      "Epoch 860: perda treino: 1.2571248930726142e-08\n",
      "Epoch 861: perda treino: 1.2538993843236312e-08\n",
      "Epoch 862: perda treino: 1.2522866299491398e-08\n",
      "Epoch 863: perda treino: 1.2506736979389643e-08\n",
      "Epoch 864: perda treino: 1.2474481891899813e-08\n",
      "Epoch 865: perda treino: 1.2458353459976479e-08\n",
      "Epoch 866: perda treino: 1.2442225028053144e-08\n",
      "Epoch 867: perda treino: 1.2401906168690857e-08\n",
      "Epoch 868: perda treino: 1.2369651969379447e-08\n",
      "Epoch 869: perda treino: 1.232933133366032e-08\n",
      "Epoch 870: perda treino: 1.2313203789915406e-08\n",
      "Epoch 871: perda treino: 1.2289012474298033e-08\n",
      "Epoch 872: perda treino: 1.2256756498629784e-08\n",
      "Epoch 873: perda treino: 1.224062806670645e-08\n",
      "Epoch 874: perda treino: 1.2224500522961534e-08\n",
      "Epoch 875: perda treino: 1.2192243659114865e-08\n",
      "Epoch 876: perda treino: 1.2168053231675913e-08\n",
      "Epoch 877: perda treino: 1.2151924799752578e-08\n",
      "Epoch 878: perda treino: 1.2119668824084329e-08\n",
      "Epoch 879: perda treino: 1.2103540392160994e-08\n",
      "Epoch 880: perda treino: 1.208741284841608e-08\n",
      "Epoch 881: perda treino: 1.205515598456941e-08\n",
      "Epoch 882: perda treino: 1.2039028440824495e-08\n",
      "Epoch 883: perda treino: 1.202290089707958e-08\n",
      "Epoch 884: perda treino: 1.1990644033232911e-08\n",
      "Epoch 885: perda treino: 1.1958389833921501e-08\n",
      "Epoch 886: perda treino: 1.1926134746431671e-08\n",
      "Epoch 887: perda treino: 1.1869690119681309e-08\n",
      "Epoch 888: perda treino: 1.1845498804063936e-08\n",
      "Epoch 889: perda treino: 1.1829369483962182e-08\n",
      "Epoch 890: perda treino: 1.1797114396472352e-08\n",
      "Epoch 891: perda treino: 1.1756795537110065e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 892: perda treino: 1.170841379405374e-08\n",
      "Epoch 893: perda treino: 1.1692285362130406e-08\n",
      "Epoch 894: perda treino: 1.1676157818385491e-08\n",
      "Epoch 895: perda treino: 1.1643902730895661e-08\n",
      "Epoch 896: perda treino: 1.1627773410793907e-08\n",
      "Epoch 897: perda treino: 1.1611645867048992e-08\n",
      "Epoch 898: perda treino: 1.1595518323304077e-08\n",
      "Epoch 899: perda treino: 1.1539071920196875e-08\n",
      "Epoch 900: perda treino: 1.152294437645196e-08\n",
      "Epoch 901: perda treino: 1.1498752172656168e-08\n",
      "Epoch 902: perda treino: 1.1466497973344758e-08\n",
      "Epoch 903: perda treino: 1.1418116230288433e-08\n",
      "Epoch 904: perda treino: 1.1385861142798603e-08\n",
      "Epoch 905: perda treino: 1.1361669827181231e-08\n",
      "Epoch 906: perda treino: 1.1337477623385439e-08\n",
      "Epoch 907: perda treino: 1.1321350079640524e-08\n",
      "Epoch 908: perda treino: 1.130522164771719e-08\n",
      "Epoch 909: perda treino: 1.127296656022736e-08\n",
      "Epoch 910: perda treino: 1.1248775244609988e-08\n",
      "Epoch 911: perda treino: 1.1232647700865073e-08\n",
      "Epoch 912: perda treino: 1.1216518380763318e-08\n",
      "Epoch 913: perda treino: 1.1200390837018404e-08\n",
      "Epoch 914: perda treino: 1.1168134861350154e-08\n",
      "Epoch 915: perda treino: 1.115200731760524e-08\n",
      "Epoch 916: perda treino: 1.111975311829383e-08\n",
      "Epoch 917: perda treino: 1.1103624686370495e-08\n",
      "Epoch 918: perda treino: 1.108749625444716e-08\n",
      "Epoch 919: perda treino: 1.108749536626874e-08\n",
      "Epoch 920: perda treino: 1.1055239390600491e-08\n",
      "Epoch 921: perda treino: 1.1039111846855576e-08\n",
      "Epoch 922: perda treino: 1.1014920531238204e-08\n",
      "Epoch 923: perda treino: 1.0982666331926794e-08\n",
      "Epoch 924: perda treino: 1.0934284588870469e-08\n",
      "Epoch 925: perda treino: 1.0910092385074677e-08\n",
      "Epoch 926: perda treino: 1.0893964841329762e-08\n",
      "Epoch 927: perda treino: 1.0877837297584847e-08\n",
      "Epoch 928: perda treino: 1.0845581321916598e-08\n",
      "Epoch 929: perda treino: 1.0829453778171683e-08\n",
      "Epoch 930: perda treino: 1.0813326234426768e-08\n",
      "Epoch 931: perda treino: 1.0813326234426768e-08\n",
      "Epoch 932: perda treino: 1.0764943603192023e-08\n",
      "Epoch 933: perda treino: 1.0748815171268689e-08\n",
      "Epoch 934: perda treino: 1.0732686739345354e-08\n",
      "Epoch 935: perda treino: 1.0700432540033944e-08\n",
      "Epoch 936: perda treino: 1.0684304996289029e-08\n",
      "Epoch 937: perda treino: 1.065204902062078e-08\n",
      "Epoch 938: perda treino: 1.061979482130937e-08\n",
      "Epoch 939: perda treino: 1.0603666389386035e-08\n",
      "Epoch 940: perda treino: 1.058753884564112e-08\n",
      "Epoch 941: perda treino: 1.0571411301896205e-08\n",
      "Epoch 942: perda treino: 1.055528375815129e-08\n",
      "Epoch 943: perda treino: 1.0539154438049536e-08\n",
      "Epoch 944: perda treino: 1.0506899350559706e-08\n",
      "Epoch 945: perda treino: 1.0490771806814791e-08\n",
      "Epoch 946: perda treino: 1.046658049119742e-08\n",
      "Epoch 947: perda treino: 1.0450452059274085e-08\n",
      "Epoch 948: perda treino: 1.043432451552917e-08\n",
      "Epoch 949: perda treino: 1.0418196971784255e-08\n",
      "Epoch 950: perda treino: 1.040206942803934e-08\n",
      "Epoch 951: perda treino: 1.0385940996116005e-08\n",
      "Epoch 952: perda treino: 1.0353686796804595e-08\n",
      "Epoch 953: perda treino: 1.033755925305968e-08\n",
      "Epoch 954: perda treino: 1.0321430821136346e-08\n",
      "Epoch 955: perda treino: 1.0289175733646516e-08\n",
      "Epoch 956: perda treino: 1.0273048189901601e-08\n",
      "Epoch 957: perda treino: 1.0256919757978267e-08\n",
      "Epoch 958: perda treino: 1.0240792214233352e-08\n",
      "Epoch 959: perda treino: 1.0224663782310017e-08\n",
      "Epoch 960: perda treino: 1.0208535350386683e-08\n",
      "Epoch 961: perda treino: 1.0192407806641768e-08\n",
      "Epoch 962: perda treino: 1.0168216491024396e-08\n",
      "Epoch 963: perda treino: 1.015208894727948e-08\n",
      "Epoch 964: perda treino: 1.0135961403534566e-08\n",
      "Epoch 965: perda treino: 1.0119832971611231e-08\n",
      "Epoch 966: perda treino: 1.0103705427866316e-08\n",
      "Epoch 967: perda treino: 1.0055324572988411e-08\n",
      "Epoch 968: perda treino: 1.0031133257371039e-08\n",
      "Epoch 969: perda treino: 9.998878169881209e-09\n",
      "Epoch 970: perda treino: 9.982750626136294e-09\n",
      "Epoch 971: perda treino: 9.958559310518922e-09\n",
      "Epoch 972: perda treino: 9.942431766774007e-09\n",
      "Epoch 973: perda treino: 9.942431766774007e-09\n",
      "Epoch 974: perda treino: 9.90211379559014e-09\n",
      "Epoch 975: perda treino: 9.885986251845225e-09\n",
      "Epoch 976: perda treino: 9.86985781992189e-09\n",
      "Epoch 977: perda treino: 9.853730276176975e-09\n",
      "Epoch 978: perda treino: 9.83760273243206e-09\n",
      "Epoch 979: perda treino: 9.80534764494223e-09\n",
      "Epoch 980: perda treino: 9.789220101197316e-09\n",
      "Epoch 981: perda treino: 9.7730925574524e-09\n",
      "Epoch 982: perda treino: 9.756965013707486e-09\n",
      "Epoch 983: perda treino: 9.740836581784151e-09\n",
      "Epoch 984: perda treino: 9.732772809911694e-09\n",
      "Epoch 985: perda treino: 9.71664437798836e-09\n",
      "Epoch 986: perda treino: 9.700516834243444e-09\n",
      "Epoch 987: perda treino: 9.68438929049853e-09\n",
      "Epoch 988: perda treino: 9.660197974881157e-09\n",
      "Epoch 989: perda treino: 9.644070431136242e-09\n",
      "Epoch 990: perda treino: 9.627941999212908e-09\n",
      "Epoch 991: perda treino: 9.611815343646413e-09\n",
      "Epoch 992: perda treino: 9.595687799901498e-09\n",
      "Epoch 993: perda treino: 9.579560256156583e-09\n",
      "Epoch 994: perda treino: 9.563431824233248e-09\n",
      "Epoch 995: perda treino: 9.531177624921838e-09\n",
      "Epoch 996: perda treino: 9.498923425610428e-09\n",
      "Epoch 997: perda treino: 9.482794993687094e-09\n",
      "Epoch 998: perda treino: 9.466667449942179e-09\n",
      "Epoch 999: perda treino: 9.450540794375684e-09\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred = model(featuresEdges_treino)\n",
    "train_data.edge_label = torch.reshape(train_data.edge_label,(-1,1))\n",
    "\n",
    "antes_treino = criterion(y_pred, train_data.edge_label) \n",
    "\n",
    "print('Teste - perda antes do treinamento' , antes_treino.item())\n",
    "\n",
    "model.train()\n",
    "epoch = 1000\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Passe Forward\n",
    "    y_pred = model(featuresEdges_treino)\n",
    "    \n",
    "    # Computa a perda\n",
    "    loss = criterion(y_pred, train_data.edge_label)\n",
    "    \n",
    "    print('Epoch {}: perda treino: {}'.format(epoch, loss.item()))\n",
    "    \n",
    "    # Passe de Backward\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.757345971563981"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "y_pred = model(featuresEdges_teste)\n",
    "y_pred = torch.reshape(y_pred,(-1,1))\n",
    "\n",
    "threshold = torch.tensor([0.5])\n",
    "\n",
    "#Atribui 0 ou 1 de acordo com o threshold\n",
    "results = (y_pred>threshold).float()*1\n",
    "\n",
    "#reshape\n",
    "test_data.edge_label = torch.reshape(test_data.edge_label,(-1,1))\n",
    "\n",
    "#Area under the curve - AUC\n",
    "roc_auc_score(test_data.edge_label.detach().numpy(),  results.detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
