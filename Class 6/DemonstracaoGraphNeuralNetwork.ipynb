{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11536a33",
   "metadata": {},
   "source": [
    "## Demonstração Graph Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b244eedd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/thiago/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pyg\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.10.3               |   py38h578d9bd_2         3.0 MB  conda-forge\n",
      "    googledrivedownloader-0.4  |     pyhd3deb0d_1           7 KB  conda-forge\n",
      "    pyg-2.0.2                  |py38_torch_1.10.0_cu102         631 KB  pyg\n",
      "    python-louvain-0.15        |     pyhd3deb0d_0          12 KB  conda-forge\n",
      "    pytorch-cluster-1.5.9      |py38_torch_1.10.0_cu102         904 KB  pyg\n",
      "    pytorch-scatter-2.0.9      |py38_torch_1.10.0_cu102         4.7 MB  pyg\n",
      "    pytorch-sparse-0.6.12      |py38_torch_1.10.0_cu102         2.1 MB  pyg\n",
      "    pytorch-spline-conv-1.2.1  |py38_torch_1.10.0_cu102         560 KB  pyg\n",
      "    yacs-0.1.6                 |             py_0          11 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        11.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  googledrivedownlo~ conda-forge/noarch::googledrivedownloader-0.4-pyhd3deb0d_1\n",
      "  pyg                pyg/linux-64::pyg-2.0.2-py38_torch_1.10.0_cu102\n",
      "  python-louvain     conda-forge/noarch::python-louvain-0.15-pyhd3deb0d_0\n",
      "  pytorch-cluster    pyg/linux-64::pytorch-cluster-1.5.9-py38_torch_1.10.0_cu102\n",
      "  pytorch-scatter    pyg/linux-64::pytorch-scatter-2.0.9-py38_torch_1.10.0_cu102\n",
      "  pytorch-sparse     pyg/linux-64::pytorch-sparse-0.6.12-py38_torch_1.10.0_cu102\n",
      "  pytorch-spline-co~ pyg/linux-64::pytorch-spline-conv-1.2.1-py38_torch_1.10.0_cu102\n",
      "  yacs               conda-forge/noarch::yacs-0.1.6-py_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda              pkgs/main::conda-4.10.3-py38h06a4308_0 --> conda-forge::conda-4.10.3-py38h578d9bd_2\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "conda-4.10.3         | 3.0 MB    | ##################################### | 100% \n",
      "pyg-2.0.2            | 631 KB    | ##################################### | 100% \n",
      "yacs-0.1.6           | 11 KB     | ##################################### | 100% \n",
      "pytorch-spline-conv- | 560 KB    | ##################################### | 100% \n",
      "pytorch-sparse-0.6.1 | 2.1 MB    | ##################################### | 100% \n",
      "googledrivedownloade | 7 KB      | ##################################### | 100% \n",
      "pytorch-scatter-2.0. | 4.7 MB    | ##################################### | 100% \n",
      "pytorch-cluster-1.5. | 904 KB    | ##################################### | 100% \n",
      "python-louvain-0.15  | 12 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ganrante que as bibliotecas necessárias estrão disponíveis no jupyter\n",
    "%conda install -c pytorch pytorch torchvision\n",
    "%conda install pyg -c pyg -c conda-forge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e91f26a",
   "metadata": {},
   "source": [
    "### Recursos básicos da Pytorch Geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "02488d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3, 1], edge_index=[2, 4])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Somente para imprimir imagens locais no jupyter-notebook\n",
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3868d0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display.Image(\"imgs/grafosimples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c631e4d",
   "metadata": {},
   "source": [
    "### O objeto Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a8149ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'edge_index']\n",
      "\n",
      "tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n",
      "\n",
      "x presente no grafo\n",
      "edge_index presente no grafo\n"
     ]
    }
   ],
   "source": [
    "print(data.keys)\n",
    "\n",
    "print()\n",
    "print(data['x'])\n",
    "\n",
    "print()\n",
    "for key, item in data:\n",
    "    print(key+\" presente no grafo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3eafe035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(data.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19bc9596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(data.num_edges)\n",
    "\n",
    "\n",
    "print(data.num_node_features)\n",
    "\n",
    "\n",
    "print(data.has_isolated_nodes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b243657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranferir o objeto data para a GPU.\n",
    "device = torch.device('cuda')\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1b3496",
   "metadata": {},
   "source": [
    "### Datasets prontos disponíveis na Pytorch Geometric\n",
    "Existem vários datasets já disponíveis. É útil olhar para esses \"formatados\", pois podemos entender como os nossos datasets podem estar depois de carregados apropriadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0817ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENZYMES(600)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "751e7aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "019f82c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 168], x=[37, 3], y=[1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9f7ec8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bb9804d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "301c28b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se necessário, podemos embaralhar o dataset\n",
    "dataset = dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a819f7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENZYMES(500)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Podemos fatiar o dataset\n",
    "train_dataset = dataset[:500]\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8654c5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENZYMES(100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = dataset[500:]\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc28cb96",
   "metadata": {},
   "source": [
    "### Exemplo de dataset com um único grafo\n",
    "Este exemplo ilustra um grafo para os problemas de classificação de nós"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a21c286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cora()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93cdc1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "7\n",
      "1433\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "\n",
    "print(dataset.num_classes)\n",
    "\n",
    "print(dataset.num_node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12567b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719dcc06",
   "metadata": {},
   "source": [
    "Veja que tem os campos train_mask, val_mask e test_mask. Isso facilita a realização do treinamento e testes. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe9f7009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(data.train_mask.sum().item())\n",
    "\n",
    "print(data.val_mask.sum().item())\n",
    "\n",
    "print(data.test_mask.sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15fc60e",
   "metadata": {},
   "source": [
    "train_mask: indica quais nós serão usados para treinar (140 nós)<br>\n",
    "\n",
    "val_mask: nós para validação (500 nós),\n",
    "\n",
    "test_mask: quais nós para testar (1000 nós)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4370080",
   "metadata": {},
   "source": [
    "### Mini-batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc061852",
   "metadata": {},
   "source": [
    "Abordagem comum em redes neurais.\n",
    "\n",
    "PyG contém seu próprio torch_geometric.loader.DataLoader, que já cuida desse processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf733be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 12062], x=[3199, 21], y=[100], batch=[3199], ptr=[101])\n",
      "100\n",
      "tensor([ 0,  0,  0,  ..., 99, 99, 99])\n",
      "DataBatch(edge_index=[2, 12098], x=[3181, 21], y=[100], batch=[3181], ptr=[101])\n",
      "100\n",
      "tensor([ 0,  0,  0,  ..., 99, 99, 99])\n",
      "DataBatch(edge_index=[2, 12428], x=[3249, 21], y=[100], batch=[3249], ptr=[101])\n",
      "100\n",
      "tensor([ 0,  0,  0,  ..., 99, 99, 99])\n",
      "DataBatch(edge_index=[2, 12364], x=[3210, 21], y=[100], batch=[3210], ptr=[101])\n",
      "100\n",
      "tensor([ 0,  0,  0,  ..., 99, 99, 99])\n",
      "DataBatch(edge_index=[2, 12600], x=[3326, 21], y=[100], batch=[3326], ptr=[101])\n",
      "100\n",
      "tensor([ 0,  0,  0,  ..., 99, 99, 99])\n",
      "DataBatch(edge_index=[2, 13012], x=[3415, 21], y=[100], batch=[3415], ptr=[101])\n",
      "100\n",
      "tensor([ 0,  0,  0,  ..., 99, 99, 99])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "for batch in loader:\n",
    "    print(batch)\n",
    "    print(batch.num_graphs)\n",
    "    \n",
    "    #O atributo batch é um vetor que indica em que grafo cada nó pertence\n",
    "    print(batch.batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808cbb23",
   "metadata": {},
   "source": [
    "O atributo batch nesse objeto acima é um vetor que indica em que grafo cada nó pertence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26244d63",
   "metadata": {},
   "source": [
    "# Primeira GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4e39b38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cora()"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef307ca",
   "metadata": {},
   "source": [
    "### Define o modelo - usando uma GCN (Graph Convolution Network)\n",
    "Este modelo visa prever a classe de um determinado nó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "40fa1c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b31aab",
   "metadata": {},
   "source": [
    "### Instância do modelo e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c28151e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "1.9467878341674805\n",
      "1.9355218410491943\n",
      "1.921411395072937\n",
      "1.907836675643921\n",
      "1.8967329263687134\n",
      "1.8826631307601929\n",
      "1.8714100122451782\n",
      "1.856144666671753\n",
      "1.8595712184906006\n",
      "1.8292794227600098\n",
      "1.8173669576644897\n",
      "1.7960596084594727\n",
      "1.793837308883667\n",
      "1.7807165384292603\n",
      "1.7624996900558472\n",
      "1.728920817375183\n",
      "1.7297978401184082\n",
      "1.702613353729248\n",
      "1.684909701347351\n",
      "1.6729233264923096\n",
      "1.6644445657730103\n",
      "1.6539063453674316\n",
      "1.6197911500930786\n",
      "1.6140810251235962\n",
      "1.5984255075454712\n",
      "1.5798884630203247\n",
      "1.548060417175293\n",
      "1.5388152599334717\n",
      "1.5458635091781616\n",
      "1.498610258102417\n",
      "1.5099527835845947\n",
      "1.489545464515686\n",
      "1.4689756631851196\n",
      "1.4357341527938843\n",
      "1.4311721324920654\n",
      "1.4168801307678223\n",
      "1.3760454654693604\n",
      "1.3417479991912842\n",
      "1.3731054067611694\n",
      "1.3420567512512207\n",
      "1.3300844430923462\n",
      "1.3058937788009644\n",
      "1.3005071878433228\n",
      "1.277860403060913\n",
      "1.2525439262390137\n",
      "1.2566120624542236\n",
      "1.2187998294830322\n",
      "1.224665641784668\n",
      "1.2034837007522583\n",
      "1.1953208446502686\n",
      "1.1665434837341309\n",
      "1.1781706809997559\n",
      "1.1560086011886597\n",
      "1.1252267360687256\n",
      "1.1350270509719849\n",
      "1.1036548614501953\n",
      "1.0829814672470093\n",
      "1.081799864768982\n",
      "1.0731940269470215\n",
      "1.0624217987060547\n",
      "1.0332083702087402\n",
      "0.9984607100486755\n",
      "1.018809199333191\n",
      "0.991532027721405\n",
      "0.9818563461303711\n",
      "0.9675200581550598\n",
      "0.958665668964386\n",
      "0.9488254189491272\n",
      "0.9051617980003357\n",
      "0.9114453196525574\n",
      "0.9068705439567566\n",
      "0.9066044688224792\n",
      "0.9266393184661865\n",
      "0.9099037647247314\n",
      "0.8758312463760376\n",
      "0.8469181656837463\n",
      "0.8274056315422058\n",
      "0.8500514030456543\n",
      "0.7927141785621643\n",
      "0.8314356207847595\n",
      "0.7797178626060486\n",
      "0.7525100708007812\n",
      "0.7589579224586487\n",
      "0.797691822052002\n",
      "0.7810614705085754\n",
      "0.7205160856246948\n",
      "0.7319630980491638\n",
      "0.7078202962875366\n",
      "0.712786853313446\n",
      "0.7345731854438782\n",
      "0.6856772303581238\n",
      "0.6797749400138855\n",
      "0.7032006978988647\n",
      "0.6816563010215759\n",
      "0.7194011807441711\n",
      "0.6725696325302124\n",
      "0.6649136543273926\n",
      "0.6540977358818054\n",
      "0.6468572020530701\n",
      "0.6083351373672485\n",
      "0.6009433269500732\n",
      "0.6351237297058105\n",
      "0.6090447306632996\n",
      "0.594211757183075\n",
      "0.5897491574287415\n",
      "0.5830453038215637\n",
      "0.5781272053718567\n",
      "0.5980332493782043\n",
      "0.5731488466262817\n",
      "0.5827620625495911\n",
      "0.5694529414176941\n",
      "0.547732412815094\n",
      "0.54938143491745\n",
      "0.5366536378860474\n",
      "0.5198436975479126\n",
      "0.5156326293945312\n",
      "0.5473738312721252\n",
      "0.5006829500198364\n",
      "0.522044837474823\n",
      "0.5058646202087402\n",
      "0.4915364980697632\n",
      "0.5081964731216431\n",
      "0.45522284507751465\n",
      "0.5041525959968567\n",
      "0.46195903420448303\n",
      "0.4805893898010254\n",
      "0.47127407789230347\n",
      "0.4782254993915558\n",
      "0.44483914971351624\n",
      "0.4269290268421173\n",
      "0.44682908058166504\n",
      "0.4443850815296173\n",
      "0.4432916045188904\n",
      "0.44179850816726685\n",
      "0.4188680052757263\n",
      "0.4151212275028229\n",
      "0.4406059682369232\n",
      "0.39432457089424133\n",
      "0.4381011426448822\n",
      "0.37553438544273376\n",
      "0.4410761296749115\n",
      "0.38179653882980347\n",
      "0.3855074644088745\n",
      "0.38216161727905273\n",
      "0.34838342666625977\n",
      "0.38857537508010864\n",
      "0.38687750697135925\n",
      "0.3807324171066284\n",
      "0.34291696548461914\n",
      "0.39143288135528564\n",
      "0.3915579915046692\n",
      "0.37046656012535095\n",
      "0.3590443730354309\n",
      "0.3543212115764618\n",
      "0.3255859911441803\n",
      "0.34706777334213257\n",
      "0.34829601645469666\n",
      "0.33673447370529175\n",
      "0.3238050043582916\n",
      "0.32409343123435974\n",
      "0.29991376399993896\n",
      "0.33758723735809326\n",
      "0.3201355040073395\n",
      "0.30507802963256836\n",
      "0.33707496523857117\n",
      "0.30991795659065247\n",
      "0.30861762166023254\n",
      "0.2855357229709625\n",
      "0.33766552805900574\n",
      "0.3271890878677368\n",
      "0.3341168761253357\n",
      "0.3051741421222687\n",
      "0.3011248707771301\n",
      "0.2941424548625946\n",
      "0.27945244312286377\n",
      "0.3027404546737671\n",
      "0.3041708767414093\n",
      "0.3179093897342682\n",
      "0.2663099765777588\n",
      "0.27672967314720154\n",
      "0.2483920454978943\n",
      "0.26566457748413086\n",
      "0.2624324560165405\n",
      "0.2857339382171631\n",
      "0.28772205114364624\n",
      "0.2584495544433594\n",
      "0.30167099833488464\n",
      "0.2563956081867218\n",
      "0.2753787636756897\n",
      "0.2519981563091278\n",
      "0.2612241804599762\n",
      "0.26387274265289307\n",
      "0.24050815403461456\n",
      "0.2842675745487213\n",
      "0.2520020008087158\n",
      "0.2208697497844696\n",
      "0.2763875126838684\n",
      "0.24235428869724274\n",
      "0.2335508018732071\n",
      "0.2417767345905304\n",
      "0.24587105214595795\n",
      "0.25790953636169434\n",
      "0.2304888516664505\n",
      "0.23404960334300995\n",
      "0.23555929958820343\n",
      "0.21625658869743347\n",
      "0.2339133620262146\n",
      "0.2322961837053299\n",
      "0.2247815877199173\n",
      "0.19661739468574524\n",
      "0.2189565896987915\n",
      "0.22371241450309753\n",
      "0.19971750676631927\n",
      "0.23728111386299133\n",
      "0.2060151994228363\n",
      "0.2184879630804062\n",
      "0.2169310599565506\n",
      "0.24122467637062073\n",
      "0.21465347707271576\n",
      "0.24772943556308746\n",
      "0.19437222182750702\n",
      "0.20672157406806946\n",
      "0.21393731236457825\n",
      "0.18647973239421844\n",
      "0.18701057136058807\n",
      "0.19168132543563843\n",
      "0.19621971249580383\n",
      "0.18787457048892975\n",
      "0.18656401336193085\n",
      "0.18220755457878113\n",
      "0.2112475037574768\n",
      "0.20724624395370483\n",
      "0.20617860555648804\n",
      "0.20891563594341278\n",
      "0.201961487531662\n",
      "0.19385042786598206\n",
      "0.1695951372385025\n",
      "0.21539433300495148\n",
      "0.16360226273536682\n",
      "0.18722955882549286\n",
      "0.15720012784004211\n",
      "0.1774115413427353\n",
      "0.16595815122127533\n",
      "0.16965875029563904\n",
      "0.17685386538505554\n",
      "0.18267522752285004\n",
      "0.18602892756462097\n",
      "0.17774228751659393\n",
      "0.2049333155155182\n",
      "0.15301254391670227\n",
      "0.17272642254829407\n",
      "0.17172002792358398\n",
      "0.15823712944984436\n",
      "0.17623673379421234\n",
      "0.15168826282024384\n",
      "0.16461294889450073\n",
      "0.176326185464859\n",
      "0.16859395802021027\n",
      "0.19196562469005585\n",
      "0.1577012985944748\n",
      "0.1492338925600052\n",
      "0.17972223460674286\n",
      "0.12924334406852722\n",
      "0.17523184418678284\n",
      "0.18244075775146484\n",
      "0.14949576556682587\n",
      "0.17321954667568207\n",
      "0.18909813463687897\n",
      "0.1816079020500183\n",
      "0.15370313823223114\n",
      "0.1453535556793213\n",
      "0.17353099584579468\n",
      "0.17598193883895874\n",
      "0.1402379721403122\n",
      "0.16341949999332428\n",
      "0.16917745769023895\n",
      "0.15381988883018494\n",
      "0.15683603286743164\n",
      "0.16324128210544586\n",
      "0.16696378588676453\n",
      "0.13775363564491272\n",
      "0.15224629640579224\n",
      "0.14624372124671936\n",
      "0.14877143502235413\n",
      "0.16293832659721375\n",
      "0.14514075219631195\n",
      "0.15823614597320557\n",
      "0.13293591141700745\n",
      "0.15236587822437286\n",
      "0.1554708331823349\n",
      "0.1465636044740677\n",
      "0.1423720419406891\n",
      "0.12468418478965759\n",
      "0.14476989209651947\n",
      "0.14934293925762177\n",
      "0.14593733847141266\n",
      "0.1588214486837387\n",
      "0.1312635838985443\n",
      "0.15534238517284393\n",
      "0.14430959522724152\n",
      "0.12518194317817688\n",
      "0.1110948696732521\n",
      "0.11994018405675888\n",
      "0.13726311922073364\n",
      "0.13368849456310272\n",
      "0.13592515885829926\n",
      "0.16436903178691864\n",
      "0.1111467033624649\n",
      "0.12062186002731323\n",
      "0.1550038605928421\n",
      "0.12326347827911377\n",
      "0.12486162036657333\n",
      "0.1254396140575409\n",
      "0.12596026062965393\n",
      "0.12046292424201965\n",
      "0.12222252041101456\n",
      "0.11814696341753006\n",
      "0.14019963145256042\n",
      "0.13482126593589783\n",
      "0.14822840690612793\n",
      "0.11209052056074142\n",
      "0.1583789587020874\n",
      "0.11795389652252197\n",
      "0.10953968018293381\n",
      "0.12054147571325302\n",
      "0.12088040262460709\n",
      "0.12252768129110336\n",
      "0.1333775818347931\n",
      "0.12560607492923737\n",
      "0.10851644724607468\n",
      "0.12698128819465637\n",
      "0.10984434187412262\n",
      "0.11835990846157074\n",
      "0.13496136665344238\n",
      "0.1105131059885025\n",
      "0.1059606596827507\n",
      "0.11411633342504501\n",
      "0.10056518018245697\n",
      "0.1246664747595787\n",
      "0.08729376643896103\n",
      "0.1283140331506729\n",
      "0.10779950767755508\n",
      "0.09301674365997314\n",
      "0.12297939509153366\n",
      "0.11413119733333588\n",
      "0.12277085334062576\n",
      "0.11235426366329193\n",
      "0.10288868099451065\n",
      "0.10177306830883026\n",
      "0.1061190813779831\n",
      "0.10927140712738037\n",
      "0.12331138551235199\n",
      "0.10798195749521255\n",
      "0.12004458904266357\n",
      "0.10452282428741455\n",
      "0.10383637249469757\n",
      "0.09794479608535767\n",
      "0.11729995161294937\n",
      "0.10222630202770233\n",
      "0.09897979348897934\n",
      "0.10403621941804886\n",
      "0.09373994916677475\n",
      "0.10383902490139008\n",
      "0.11033335328102112\n",
      "0.11840412765741348\n",
      "0.10691960155963898\n",
      "0.11001691967248917\n",
      "0.11889095604419708\n",
      "0.10793609917163849\n",
      "0.09973113983869553\n",
      "0.10364492237567902\n",
      "0.11739035695791245\n",
      "0.08254621177911758\n",
      "0.10776723176240921\n",
      "0.09484662860631943\n",
      "0.12217013537883759\n",
      "0.09745702892541885\n",
      "0.11490563303232193\n",
      "0.08602748066186905\n",
      "0.08989283442497253\n",
      "0.08321838825941086\n",
      "0.08945538848638535\n",
      "0.1060580238699913\n",
      "0.11148600280284882\n",
      "0.10402072966098785\n",
      "0.09715372323989868\n",
      "0.11380736529827118\n",
      "0.10016452521085739\n",
      "0.0863659605383873\n",
      "0.09249206632375717\n",
      "0.10207998752593994\n",
      "0.08567847311496735\n",
      "0.07327298820018768\n",
      "0.08709237724542618\n",
      "0.10086482018232346\n",
      "0.08041656017303467\n",
      "0.06818315386772156\n",
      "0.0873623639345169\n",
      "0.09068718552589417\n",
      "0.09733021259307861\n",
      "0.09255024045705795\n",
      "0.0903596580028534\n",
      "0.08924376964569092\n",
      "0.09611333906650543\n",
      "0.12963268160820007\n",
      "0.09062622487545013\n",
      "0.0730447769165039\n",
      "0.08585226535797119\n",
      "0.08996801823377609\n",
      "0.09156381338834763\n",
      "0.07750163227319717\n",
      "0.08888954669237137\n",
      "0.10139049589633942\n",
      "0.09146158397197723\n",
      "0.08668319135904312\n",
      "0.08018482476472855\n",
      "0.09121813625097275\n",
      "0.08071378618478775\n",
      "0.11241140961647034\n",
      "0.0951058492064476\n",
      "0.08562183380126953\n",
      "0.08743751049041748\n",
      "0.07925388216972351\n",
      "0.07408981770277023\n",
      "0.08520906418561935\n",
      "0.06295247375965118\n",
      "0.07501891255378723\n",
      "0.08977319300174713\n",
      "0.08656167984008789\n",
      "0.09410355240106583\n",
      "0.06724168360233307\n",
      "0.0845027044415474\n",
      "0.08231149613857269\n",
      "0.08602748811244965\n",
      "0.09218944609165192\n",
      "0.07654125243425369\n",
      "0.10237853974103928\n",
      "0.07688844203948975\n",
      "0.08592008799314499\n",
      "0.09632105380296707\n",
      "0.07902097702026367\n",
      "0.06520258635282516\n",
      "0.07210997492074966\n",
      "0.08909137547016144\n",
      "0.10256868600845337\n",
      "0.08715155720710754\n",
      "0.0872671976685524\n",
      "0.09228198975324631\n",
      "0.08170545846223831\n",
      "0.08618797361850739\n",
      "0.0835619792342186\n",
      "0.06966565549373627\n",
      "0.06277382373809814\n",
      "0.07393526285886765\n",
      "0.06635836511850357\n",
      "0.07453444600105286\n",
      "0.09153099358081818\n",
      "0.08082089573144913\n",
      "0.07915180921554565\n",
      "0.08856602013111115\n",
      "0.09174828976392746\n",
      "0.09899111837148666\n",
      "0.07496217638254166\n",
      "0.06984879821538925\n",
      "0.07579319179058075\n",
      "0.07287076860666275\n",
      "0.07214493304491043\n",
      "0.07970122247934341\n",
      "0.07645941525697708\n",
      "0.06329718977212906\n",
      "0.06614794582128525\n",
      "0.08399751037359238\n",
      "0.07401172816753387\n",
      "0.07009865343570709\n",
      "0.0758889690041542\n",
      "0.08554979413747787\n",
      "0.07850175350904465\n",
      "0.06883713603019714\n",
      "0.07453779131174088\n",
      "0.0700451210141182\n",
      "0.09113644063472748\n",
      "0.07641632854938507\n",
      "0.09305174648761749\n",
      "0.0767546072602272\n",
      "0.06586719304323196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07670948654413223\n",
      "0.06948340684175491\n",
      "0.07660390436649323\n",
      "0.054722998291254044\n",
      "0.07035963237285614\n",
      "0.08656001091003418\n",
      "0.07505828142166138\n",
      "0.06700588762760162\n",
      "0.06638293713331223\n",
      "0.06317857652902603\n",
      "0.06284555047750473\n",
      "0.06690523773431778\n",
      "0.08742665499448776\n",
      "0.08199400454759598\n",
      "0.059563975781202316\n",
      "0.09186728298664093\n",
      "0.06790531426668167\n",
      "0.08087696880102158\n",
      "0.06791532039642334\n",
      "0.10194491595029831\n",
      "0.0902557298541069\n",
      "0.07325106859207153\n",
      "0.05990366265177727\n",
      "0.07124272733926773\n",
      "0.07073567807674408\n",
      "0.07185263931751251\n",
      "0.0694717988371849\n",
      "0.08313532918691635\n",
      "0.07213036715984344\n",
      "0.059142474085092545\n",
      "0.05817675590515137\n",
      "0.06310446560382843\n",
      "0.07192075997591019\n",
      "0.07435303181409836\n",
      "0.05971919372677803\n",
      "0.07496654987335205\n",
      "0.05084991455078125\n",
      "0.06317513436079025\n",
      "0.054398395121097565\n",
      "0.05213503539562225\n",
      "0.08066413551568985\n",
      "0.06750611215829849\n",
      "0.0731574296951294\n",
      "0.07619885355234146\n",
      "0.0773710235953331\n",
      "0.08129887282848358\n",
      "0.07843761146068573\n",
      "0.05774558708071709\n",
      "0.0764961838722229\n",
      "0.059873316437006\n",
      "0.05928236246109009\n",
      "0.07617399096488953\n",
      "0.06004852056503296\n",
      "0.06535166501998901\n",
      "0.0600859709084034\n",
      "0.06619849056005478\n",
      "0.05909363925457001\n",
      "0.08467511087656021\n",
      "0.053861524909734726\n",
      "0.06250827014446259\n",
      "0.07705947756767273\n",
      "0.06546502560377121\n",
      "0.0657811239361763\n",
      "0.0791892260313034\n",
      "0.05820159986615181\n",
      "0.05680013820528984\n",
      "0.059994712471961975\n",
      "0.08383755385875702\n",
      "0.06607875227928162\n",
      "0.07539771497249603\n",
      "0.08041425794363022\n",
      "0.07343574613332748\n",
      "0.0687110647559166\n",
      "0.06931626051664352\n",
      "0.06904932856559753\n",
      "0.07268469780683517\n",
      "0.07742311805486679\n",
      "0.05939384922385216\n",
      "0.05268005654215813\n",
      "0.06410536170005798\n",
      "0.054156869649887085\n",
      "0.07588964700698853\n",
      "0.06237039715051651\n",
      "0.05774524435400963\n",
      "0.06329961866140366\n",
      "0.07086067646741867\n",
      "0.07434556633234024\n",
      "0.05192406103014946\n",
      "0.057207658886909485\n",
      "0.05580316483974457\n",
      "0.055860791355371475\n",
      "0.09007419645786285\n",
      "0.06525734812021255\n",
      "0.06342216581106186\n",
      "0.0707637295126915\n",
      "0.05430234968662262\n",
      "0.056340474635362625\n",
      "0.07695074379444122\n",
      "0.07597088813781738\n",
      "0.07432238757610321\n",
      "0.05898084118962288\n",
      "0.06819052249193192\n",
      "0.061098434031009674\n",
      "0.04806305468082428\n",
      "0.06808500736951828\n",
      "0.058803264051675797\n",
      "0.06126222014427185\n",
      "0.06715458631515503\n",
      "0.05373988673090935\n",
      "0.06194419041275978\n",
      "0.06301099807024002\n",
      "0.05016317963600159\n",
      "0.050916433334350586\n",
      "0.05622877553105354\n",
      "0.05835089087486267\n",
      "0.050978101789951324\n",
      "0.0648750513792038\n",
      "0.05634507164359093\n",
      "0.054698795080184937\n",
      "0.049425456672906876\n",
      "0.064096599817276\n",
      "0.07705504447221756\n",
      "0.07093621045351028\n",
      "0.05518268048763275\n",
      "0.07569609582424164\n",
      "0.08603480458259583\n",
      "0.05814747139811516\n",
      "0.07091081887483597\n",
      "0.05991717800498009\n",
      "0.057732950896024704\n",
      "0.06294697523117065\n",
      "0.057211603969335556\n",
      "0.06334906816482544\n",
      "0.05834954231977463\n",
      "0.06688519567251205\n",
      "0.05453091859817505\n",
      "0.05486585199832916\n",
      "0.047969844192266464\n",
      "0.0542612262070179\n",
      "0.05405229702591896\n",
      "0.05299512669444084\n",
      "0.07174167782068253\n",
      "0.04967191815376282\n",
      "0.06773850321769714\n",
      "0.053649332374334335\n",
      "0.05863774195313454\n",
      "0.07148468494415283\n",
      "0.0611710362136364\n",
      "0.05751252919435501\n",
      "0.057932786643505096\n",
      "0.06185067072510719\n",
      "0.049997031688690186\n",
      "0.05595511198043823\n",
      "0.043021343648433685\n",
      "0.06204267218708992\n",
      "0.049420930445194244\n",
      "0.05804433673620224\n",
      "0.05823620408773422\n",
      "0.04710649698972702\n",
      "0.04769021272659302\n",
      "0.05676878243684769\n",
      "0.05750976875424385\n",
      "0.06821395456790924\n",
      "0.06481534242630005\n",
      "0.056891608983278275\n",
      "0.05091254785656929\n",
      "0.06631823629140854\n",
      "0.05410011112689972\n",
      "0.06523514539003372\n",
      "0.05784448981285095\n",
      "0.06775282323360443\n",
      "0.05118729919195175\n",
      "0.06139253079891205\n",
      "0.05512490123510361\n",
      "0.047669749706983566\n",
      "0.07171108573675156\n",
      "0.05639712139964104\n",
      "0.06786178797483444\n",
      "0.0737064853310585\n",
      "0.04017634689807892\n",
      "0.0562778115272522\n",
      "0.06448832899332047\n",
      "0.051622677594423294\n",
      "0.0807962566614151\n",
      "0.06915908306837082\n",
      "0.04452864080667496\n",
      "0.05523297190666199\n",
      "0.07266117632389069\n",
      "0.05233274772763252\n",
      "0.05422978848218918\n",
      "0.05243493244051933\n",
      "0.05184376612305641\n",
      "0.0618651919066906\n",
      "0.04103871434926987\n",
      "0.04919946566224098\n",
      "0.06020481884479523\n",
      "0.058673325926065445\n",
      "0.05142754316329956\n",
      "0.045434705913066864\n",
      "0.039935383945703506\n",
      "0.059484101831912994\n",
      "0.0486474446952343\n",
      "0.043751731514930725\n",
      "0.04076051712036133\n",
      "0.042741674929857254\n",
      "0.048476558178663254\n",
      "0.05538337677717209\n",
      "0.053120389580726624\n",
      "0.04499903693795204\n",
      "0.060100335627794266\n",
      "0.05795429274439812\n",
      "0.0577833391726017\n",
      "0.05652768909931183\n",
      "0.04576052352786064\n",
      "0.06659622490406036\n",
      "0.05005739629268646\n",
      "0.05019235610961914\n",
      "0.05581558123230934\n",
      "0.0445968434214592\n",
      "0.06481540948152542\n",
      "0.04623762145638466\n",
      "0.06796904653310776\n",
      "0.05873913690447807\n",
      "0.05180088058114052\n",
      "0.05175646394491196\n",
      "0.0492778941988945\n",
      "0.047258686274290085\n",
      "0.037388045340776443\n",
      "0.05864955857396126\n",
      "0.05972810462117195\n",
      "0.03744974359869957\n",
      "0.04210947826504707\n",
      "0.04579880088567734\n",
      "0.04757660999894142\n",
      "0.06779696047306061\n",
      "0.052085865288972855\n",
      "0.05410066246986389\n",
      "0.046716220676898956\n",
      "0.051052045077085495\n",
      "0.0475197471678257\n",
      "0.03705620393157005\n",
      "0.05895790457725525\n",
      "0.05692417919635773\n",
      "0.036619365215301514\n",
      "0.05417151004076004\n",
      "0.05171254649758339\n",
      "0.048740968108177185\n",
      "0.047955092042684555\n",
      "0.04621151462197304\n",
      "0.0639764592051506\n",
      "0.04276005178689957\n",
      "0.05276266485452652\n",
      "0.05721154063940048\n",
      "0.04649623483419418\n",
      "0.05427555739879608\n",
      "0.04632311314344406\n",
      "0.07323706150054932\n",
      "0.059726592153310776\n",
      "0.03993095085024834\n",
      "0.04553870111703873\n",
      "0.051267191767692566\n",
      "0.04439565911889076\n",
      "0.046253543347120285\n",
      "0.052701257169246674\n",
      "0.05449945107102394\n",
      "0.06785193085670471\n",
      "0.05352451279759407\n",
      "0.038816288113594055\n",
      "0.047871097922325134\n",
      "0.0504448227584362\n",
      "0.0486275814473629\n",
      "0.050212759524583817\n",
      "0.06334411352872849\n",
      "0.04411311447620392\n",
      "0.06625950336456299\n",
      "0.0483824647963047\n",
      "0.060799721628427505\n",
      "0.05562340095639229\n",
      "0.029138466343283653\n",
      "0.05459564924240112\n",
      "0.061927877366542816\n",
      "0.052598316222429276\n",
      "0.06044668331742287\n",
      "0.06731785088777542\n",
      "0.04672245681285858\n",
      "0.03834105655550957\n",
      "0.033609889447689056\n",
      "0.049618061631917953\n",
      "0.033210575580596924\n",
      "0.042373597621917725\n",
      "0.0689258873462677\n",
      "0.05360034853219986\n",
      "0.054632507264614105\n",
      "0.03865152597427368\n",
      "0.05385209247469902\n",
      "0.05839664489030838\n",
      "0.049548957496881485\n",
      "0.05015424266457558\n",
      "0.05386856198310852\n",
      "0.058920688927173615\n",
      "0.04336496815085411\n",
      "0.03759405016899109\n",
      "0.04940288886427879\n",
      "0.06539499759674072\n",
      "0.056504685431718826\n",
      "0.047621190547943115\n",
      "0.05108042061328888\n",
      "0.04550791159272194\n",
      "0.0508108027279377\n",
      "0.059310197830200195\n",
      "0.044811490923166275\n",
      "0.05493774637579918\n",
      "0.03386547416448593\n",
      "0.04383823648095131\n",
      "0.03576572984457016\n",
      "0.05161381885409355\n",
      "0.05435781180858612\n",
      "0.049526702612638474\n",
      "0.03569594770669937\n",
      "0.03860722482204437\n",
      "0.036358729004859924\n",
      "0.042477693408727646\n",
      "0.04891713336110115\n",
      "0.0520804263651371\n",
      "0.05355062708258629\n",
      "0.034099187701940536\n",
      "0.04675272852182388\n",
      "0.04279213398694992\n",
      "0.05183098092675209\n",
      "0.03988099470734596\n",
      "0.031914062798023224\n",
      "0.04435199126601219\n",
      "0.03767819330096245\n",
      "0.04806972295045853\n",
      "0.038343362510204315\n",
      "0.03664431720972061\n",
      "0.03916216269135475\n",
      "0.042337071150541306\n",
      "0.04240026697516441\n",
      "0.05238431692123413\n",
      "0.050387732684612274\n",
      "0.04703565686941147\n",
      "0.04510537534952164\n",
      "0.05699492245912552\n",
      "0.04758503660559654\n",
      "0.050009384751319885\n",
      "0.04404018074274063\n",
      "0.04115315526723862\n",
      "0.04894854128360748\n",
      "0.05010206252336502\n",
      "0.038802117109298706\n",
      "0.04215987026691437\n",
      "0.04597202688455582\n",
      "0.045605938881635666\n",
      "0.035466041415929794\n",
      "0.042741596698760986\n",
      "0.05123765021562576\n",
      "0.046300310641527176\n",
      "0.053466059267520905\n",
      "0.045139510184526443\n",
      "0.04329119250178337\n",
      "0.05356437340378761\n",
      "0.04431813582777977\n",
      "0.05476222187280655\n",
      "0.03673110902309418\n",
      "0.04172389209270477\n",
      "0.03481404110789299\n",
      "0.046572547405958176\n",
      "0.05647813156247139\n",
      "0.04804811626672745\n",
      "0.046096641570329666\n",
      "0.05161060020327568\n",
      "0.0559406578540802\n",
      "0.05264217033982277\n",
      "0.04910222440958023\n",
      "0.03290799260139465\n",
      "0.05874272808432579\n",
      "0.04999929666519165\n",
      "0.032738491892814636\n",
      "0.05137358233332634\n",
      "0.03830651938915253\n",
      "0.04532498121261597\n",
      "0.04011503607034683\n",
      "0.044190023094415665\n",
      "0.04020640626549721\n",
      "0.040645428001880646\n",
      "0.04207638278603554\n",
      "0.023996196687221527\n",
      "0.036860328167676926\n",
      "0.06035701185464859\n",
      "0.04580956697463989\n",
      "0.053736794739961624\n",
      "0.05561009794473648\n",
      "0.05346772447228432\n",
      "0.0556023083627224\n",
      "0.041297655552625656\n",
      "0.03860456869006157\n",
      "0.03264206647872925\n",
      "0.060839906334877014\n",
      "0.05608266219496727\n",
      "0.04041087627410889\n",
      "0.03775201737880707\n",
      "0.04003087431192398\n",
      "0.043988097459077835\n",
      "0.042270515114068985\n",
      "0.04846765100955963\n",
      "0.045639947056770325\n",
      "0.06000906974077225\n",
      "0.03349434956908226\n",
      "0.045994579792022705\n",
      "0.0501960925757885\n",
      "0.04719005897641182\n",
      "0.04681577533483505\n",
      "0.04139477759599686\n",
      "0.04415625333786011\n",
      "0.0499948114156723\n",
      "0.046780019998550415\n",
      "0.037457093596458435\n",
      "0.05218597501516342\n",
      "0.05270839482545853\n",
      "0.03617490455508232\n",
      "0.04996252804994583\n",
      "0.03421112522482872\n",
      "0.04595405235886574\n",
      "0.04454611614346504\n",
      "0.04324275627732277\n",
      "0.04192199185490608\n",
      "0.03815092518925667\n",
      "0.03360828757286072\n",
      "0.04571547359228134\n",
      "0.03683032840490341\n",
      "0.03772353008389473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04186541587114334\n",
      "0.05124534294009209\n",
      "0.03814320266246796\n",
      "0.038243234157562256\n",
      "0.05580493062734604\n",
      "0.06160861998796463\n",
      "0.049163736402988434\n",
      "0.02821393869817257\n",
      "0.04852129891514778\n",
      "0.031808942556381226\n",
      "0.03678324818611145\n",
      "0.049377575516700745\n",
      "0.026541225612163544\n",
      "0.036520201712846756\n",
      "0.042909614741802216\n",
      "0.04684627801179886\n",
      "0.04992172494530678\n",
      "0.03716209903359413\n",
      "0.0462457612156868\n",
      "0.03127414360642433\n",
      "0.035708919167518616\n",
      "0.047380294650793076\n",
      "0.0445268340408802\n",
      "0.028578298166394234\n",
      "0.052184589207172394\n",
      "0.04663683474063873\n",
      "0.051812976598739624\n",
      "0.03311019018292427\n",
      "0.04958309605717659\n",
      "0.03530464321374893\n",
      "0.03325691446661949\n",
      "0.05040210485458374\n",
      "0.040966156870126724\n",
      "0.045886337757110596\n",
      "0.03991462662816048\n",
      "0.04287309944629669\n",
      "0.03335613012313843\n",
      "0.027773087844252586\n",
      "0.04748795926570892\n",
      "0.042115576565265656\n",
      "0.04760550335049629\n",
      "0.03974761441349983\n",
      "0.034785542637109756\n",
      "0.04173411801457405\n",
      "0.03749449923634529\n",
      "0.03176550194621086\n",
      "0.027531197294592857\n",
      "0.04762059077620506\n",
      "0.0372777096927166\n",
      "0.029755009338259697\n",
      "0.044114768505096436\n",
      "0.02048259973526001\n",
      "0.04716777428984642\n",
      "0.049916643649339676\n",
      "0.039765406399965286\n",
      "0.046329982578754425\n",
      "0.0385780893266201\n",
      "0.040084268897771835\n",
      "0.040529850870370865\n",
      "0.05376242473721504\n",
      "0.03723187744617462\n",
      "0.03527500480413437\n",
      "0.03501281514763832\n",
      "0.04552990198135376\n",
      "0.03674047440290451\n",
      "0.03854851424694061\n",
      "0.03692404925823212\n",
      "0.0352041982114315\n",
      "0.04177873954176903\n",
      "0.038574639707803726\n",
      "0.03921905532479286\n",
      "0.03442835062742233\n",
      "0.04346524551510811\n",
      "0.05059558153152466\n",
      "0.03282837197184563\n",
      "0.04422047361731529\n",
      "0.0361136794090271\n",
      "0.0487951822578907\n",
      "0.038244541734457016\n",
      "0.04197067767381668\n",
      "0.054748840630054474\n",
      "0.03720720857381821\n",
      "0.04844262823462486\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001,  weight_decay=5e-4)\n",
    "\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    \n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88066165",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "750eef0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8030\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eaa599",
   "metadata": {},
   "source": [
    "# Link prediction - com GAE (Graph AutoEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42c9a8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 8446], y=[2708], pos_edge_label=[1055], pos_edge_label_index=[2, 1055], neg_edge_label=[1055], neg_edge_label_index=[2, 1055])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch_geometric.transforms as T\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn import ReLU\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "data.train_mask = data.val_mask = data.test_mask = None\n",
    "\n",
    "transform = T.RandomLinkSplit(is_undirected=True,add_negative_train_samples=True,split_labels=True)\n",
    "train_data, val_data, test_data = transform(data)\n",
    "train_data = train_data.to(device)\n",
    "val_data=val_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3455fe9c",
   "metadata": {},
   "source": [
    "### Define o encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8e867f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True) # cached apenas para transductive learning\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True) # cached apenas para transductive learning\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc76b12",
   "metadata": {},
   "source": [
    "### Define o autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "769e8929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAE(\n",
      "  (encoder): GCNEncoder(\n",
      "    (conv1): GCNConv(1433, 4)\n",
      "    (conv2): GCNConv(4, 2)\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GAE\n",
    "\n",
    "# parâmetros\n",
    "out_channels = 2\n",
    "num_features = dataset.num_features\n",
    "epochs = 100\n",
    "\n",
    "# modelo\n",
    "model = GAE(GCNEncoder(num_features, out_channels))\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "x = train_data.x.to(device)\n",
    "\n",
    "train_pos_edge_index = train_data.pos_edge_label_index.to(device)\n",
    "\n",
    "# inicialização o optimizador\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e89568",
   "metadata": {},
   "source": [
    "### Treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87ad70ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d62ce73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, AUC: 0.9103, AP: 0.9300\n",
      "Epoch: 002, AUC: 0.9102, AP: 0.9301\n",
      "Epoch: 003, AUC: 0.9096, AP: 0.9299\n",
      "Epoch: 004, AUC: 0.9087, AP: 0.9295\n",
      "Epoch: 005, AUC: 0.9078, AP: 0.9291\n",
      "Epoch: 006, AUC: 0.9075, AP: 0.9289\n",
      "Epoch: 007, AUC: 0.9075, AP: 0.9289\n",
      "Epoch: 008, AUC: 0.9071, AP: 0.9285\n",
      "Epoch: 009, AUC: 0.9069, AP: 0.9284\n",
      "Epoch: 010, AUC: 0.9063, AP: 0.9280\n",
      "Epoch: 011, AUC: 0.9062, AP: 0.9281\n",
      "Epoch: 012, AUC: 0.9060, AP: 0.9282\n",
      "Epoch: 013, AUC: 0.9060, AP: 0.9281\n",
      "Epoch: 014, AUC: 0.9062, AP: 0.9283\n",
      "Epoch: 015, AUC: 0.9061, AP: 0.9283\n",
      "Epoch: 016, AUC: 0.9062, AP: 0.9284\n",
      "Epoch: 017, AUC: 0.9057, AP: 0.9280\n",
      "Epoch: 018, AUC: 0.9055, AP: 0.9279\n",
      "Epoch: 019, AUC: 0.9053, AP: 0.9278\n",
      "Epoch: 020, AUC: 0.9051, AP: 0.9274\n",
      "Epoch: 021, AUC: 0.9052, AP: 0.9275\n",
      "Epoch: 022, AUC: 0.9051, AP: 0.9272\n",
      "Epoch: 023, AUC: 0.9050, AP: 0.9271\n",
      "Epoch: 024, AUC: 0.9049, AP: 0.9269\n",
      "Epoch: 025, AUC: 0.9049, AP: 0.9269\n",
      "Epoch: 026, AUC: 0.9049, AP: 0.9268\n",
      "Epoch: 027, AUC: 0.9050, AP: 0.9267\n",
      "Epoch: 028, AUC: 0.9048, AP: 0.9265\n",
      "Epoch: 029, AUC: 0.9046, AP: 0.9263\n",
      "Epoch: 030, AUC: 0.9040, AP: 0.9259\n",
      "Epoch: 031, AUC: 0.9034, AP: 0.9256\n",
      "Epoch: 032, AUC: 0.9028, AP: 0.9252\n",
      "Epoch: 033, AUC: 0.9022, AP: 0.9248\n",
      "Epoch: 034, AUC: 0.9013, AP: 0.9243\n",
      "Epoch: 035, AUC: 0.9005, AP: 0.9240\n",
      "Epoch: 036, AUC: 0.9000, AP: 0.9237\n",
      "Epoch: 037, AUC: 0.9001, AP: 0.9237\n",
      "Epoch: 038, AUC: 0.9002, AP: 0.9237\n",
      "Epoch: 039, AUC: 0.9007, AP: 0.9239\n",
      "Epoch: 040, AUC: 0.9009, AP: 0.9241\n",
      "Epoch: 041, AUC: 0.9002, AP: 0.9238\n",
      "Epoch: 042, AUC: 0.9000, AP: 0.9238\n",
      "Epoch: 043, AUC: 0.8998, AP: 0.9239\n",
      "Epoch: 044, AUC: 0.8996, AP: 0.9239\n",
      "Epoch: 045, AUC: 0.8993, AP: 0.9237\n",
      "Epoch: 046, AUC: 0.8992, AP: 0.9235\n",
      "Epoch: 047, AUC: 0.8994, AP: 0.9235\n",
      "Epoch: 048, AUC: 0.8999, AP: 0.9236\n",
      "Epoch: 049, AUC: 0.9001, AP: 0.9237\n",
      "Epoch: 050, AUC: 0.8998, AP: 0.9234\n",
      "Epoch: 051, AUC: 0.8990, AP: 0.9230\n",
      "Epoch: 052, AUC: 0.8981, AP: 0.9224\n",
      "Epoch: 053, AUC: 0.8972, AP: 0.9219\n",
      "Epoch: 054, AUC: 0.8966, AP: 0.9217\n",
      "Epoch: 055, AUC: 0.8965, AP: 0.9217\n",
      "Epoch: 056, AUC: 0.8963, AP: 0.9216\n",
      "Epoch: 057, AUC: 0.8966, AP: 0.9217\n",
      "Epoch: 058, AUC: 0.8971, AP: 0.9220\n",
      "Epoch: 059, AUC: 0.8976, AP: 0.9222\n",
      "Epoch: 060, AUC: 0.8976, AP: 0.9221\n",
      "Epoch: 061, AUC: 0.8969, AP: 0.9217\n",
      "Epoch: 062, AUC: 0.8962, AP: 0.9212\n",
      "Epoch: 063, AUC: 0.8953, AP: 0.9206\n",
      "Epoch: 064, AUC: 0.8949, AP: 0.9204\n",
      "Epoch: 065, AUC: 0.8950, AP: 0.9202\n",
      "Epoch: 066, AUC: 0.8956, AP: 0.9206\n",
      "Epoch: 067, AUC: 0.8962, AP: 0.9209\n",
      "Epoch: 068, AUC: 0.8965, AP: 0.9210\n",
      "Epoch: 069, AUC: 0.8965, AP: 0.9211\n",
      "Epoch: 070, AUC: 0.8963, AP: 0.9208\n",
      "Epoch: 071, AUC: 0.8955, AP: 0.9202\n",
      "Epoch: 072, AUC: 0.8949, AP: 0.9198\n",
      "Epoch: 073, AUC: 0.8947, AP: 0.9197\n",
      "Epoch: 074, AUC: 0.8946, AP: 0.9197\n",
      "Epoch: 075, AUC: 0.8950, AP: 0.9201\n",
      "Epoch: 076, AUC: 0.8952, AP: 0.9202\n",
      "Epoch: 077, AUC: 0.8955, AP: 0.9204\n",
      "Epoch: 078, AUC: 0.8950, AP: 0.9200\n",
      "Epoch: 079, AUC: 0.8941, AP: 0.9195\n",
      "Epoch: 080, AUC: 0.8933, AP: 0.9191\n",
      "Epoch: 081, AUC: 0.8930, AP: 0.9191\n",
      "Epoch: 082, AUC: 0.8930, AP: 0.9191\n",
      "Epoch: 083, AUC: 0.8933, AP: 0.9193\n",
      "Epoch: 084, AUC: 0.8937, AP: 0.9195\n",
      "Epoch: 085, AUC: 0.8940, AP: 0.9199\n",
      "Epoch: 086, AUC: 0.8939, AP: 0.9200\n",
      "Epoch: 087, AUC: 0.8935, AP: 0.9200\n",
      "Epoch: 088, AUC: 0.8924, AP: 0.9195\n",
      "Epoch: 089, AUC: 0.8914, AP: 0.9190\n",
      "Epoch: 090, AUC: 0.8909, AP: 0.9189\n",
      "Epoch: 091, AUC: 0.8905, AP: 0.9187\n",
      "Epoch: 092, AUC: 0.8897, AP: 0.9182\n",
      "Epoch: 093, AUC: 0.8894, AP: 0.9180\n",
      "Epoch: 094, AUC: 0.8891, AP: 0.9180\n",
      "Epoch: 095, AUC: 0.8889, AP: 0.9180\n",
      "Epoch: 096, AUC: 0.8882, AP: 0.9178\n",
      "Epoch: 097, AUC: 0.8877, AP: 0.9175\n",
      "Epoch: 098, AUC: 0.8874, AP: 0.9173\n",
      "Epoch: 099, AUC: 0.8872, AP: 0.9171\n",
      "Epoch: 100, AUC: 0.8872, AP: 0.9171\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "\n",
    "    auc, ap = test(val_data.pos_edge_label_index, val_data.neg_edge_label_index)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd8a589b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8820, AP: 0.9116\n"
     ]
    }
   ],
   "source": [
    "#Teste\n",
    "auc, ap = test(test_data.pos_edge_label_index, test_data.neg_edge_label_index)\n",
    "print('AUC: {:.4f}, AP: {:.4f}'.format( auc, ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49309ce9",
   "metadata": {},
   "source": [
    "## Demonstração do Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3467bf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b9783bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d59e52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAE(\n",
      "  (encoder): GCNEncoder(\n",
      "    (conv1): GCNConv(1433, 128)\n",
      "    (conv2): GCNConv(128, 64)\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Copiei as informações anteriores\n",
    "\n",
    "# parâmetros \n",
    "out_channels = 64\n",
    "num_features = dataset.num_features\n",
    "epochs = 100\n",
    "\n",
    "# modelo\n",
    "model = GAE(GCNEncoder(num_features, out_channels))\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "x = train_data.x.to(device)\n",
    "\n",
    "train_pos_edge_index = train_data.pos_edge_label_index.to(device)\n",
    "\n",
    "# inicialização o optimizador\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d18fd71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local onde os experimentos serão salvos\n",
    "writer = SummaryWriter('experimentos/modelo_GAE3_'+'64d_100_epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ee82f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, AUC: 0.8033, AP: 0.8233\n",
      "Epoch: 002, AUC: 0.7415, AP: 0.7593\n",
      "Epoch: 003, AUC: 0.8567, AP: 0.8662\n",
      "Epoch: 004, AUC: 0.8148, AP: 0.8273\n",
      "Epoch: 005, AUC: 0.8076, AP: 0.8251\n",
      "Epoch: 006, AUC: 0.8203, AP: 0.8401\n",
      "Epoch: 007, AUC: 0.8275, AP: 0.8476\n",
      "Epoch: 008, AUC: 0.8287, AP: 0.8486\n",
      "Epoch: 009, AUC: 0.8289, AP: 0.8481\n",
      "Epoch: 010, AUC: 0.8292, AP: 0.8476\n",
      "Epoch: 011, AUC: 0.8300, AP: 0.8456\n",
      "Epoch: 012, AUC: 0.8336, AP: 0.8449\n",
      "Epoch: 013, AUC: 0.8435, AP: 0.8526\n",
      "Epoch: 014, AUC: 0.8559, AP: 0.8642\n",
      "Epoch: 015, AUC: 0.8654, AP: 0.8742\n",
      "Epoch: 016, AUC: 0.8710, AP: 0.8797\n",
      "Epoch: 017, AUC: 0.8750, AP: 0.8839\n",
      "Epoch: 018, AUC: 0.8795, AP: 0.8881\n",
      "Epoch: 019, AUC: 0.8843, AP: 0.8923\n",
      "Epoch: 020, AUC: 0.8874, AP: 0.8951\n",
      "Epoch: 021, AUC: 0.8915, AP: 0.8991\n",
      "Epoch: 022, AUC: 0.8951, AP: 0.9031\n",
      "Epoch: 023, AUC: 0.8979, AP: 0.9065\n",
      "Epoch: 024, AUC: 0.8996, AP: 0.9085\n",
      "Epoch: 025, AUC: 0.9011, AP: 0.9103\n",
      "Epoch: 026, AUC: 0.9025, AP: 0.9121\n",
      "Epoch: 027, AUC: 0.9037, AP: 0.9140\n",
      "Epoch: 028, AUC: 0.9048, AP: 0.9159\n",
      "Epoch: 029, AUC: 0.9057, AP: 0.9171\n",
      "Epoch: 030, AUC: 0.9069, AP: 0.9188\n",
      "Epoch: 031, AUC: 0.9078, AP: 0.9200\n",
      "Epoch: 032, AUC: 0.9084, AP: 0.9206\n",
      "Epoch: 033, AUC: 0.9089, AP: 0.9213\n",
      "Epoch: 034, AUC: 0.9092, AP: 0.9217\n",
      "Epoch: 035, AUC: 0.9099, AP: 0.9225\n",
      "Epoch: 036, AUC: 0.9103, AP: 0.9231\n",
      "Epoch: 037, AUC: 0.9107, AP: 0.9236\n",
      "Epoch: 038, AUC: 0.9113, AP: 0.9241\n",
      "Epoch: 039, AUC: 0.9119, AP: 0.9247\n",
      "Epoch: 040, AUC: 0.9128, AP: 0.9255\n",
      "Epoch: 041, AUC: 0.9138, AP: 0.9265\n",
      "Epoch: 042, AUC: 0.9144, AP: 0.9271\n",
      "Epoch: 043, AUC: 0.9150, AP: 0.9275\n",
      "Epoch: 044, AUC: 0.9151, AP: 0.9277\n",
      "Epoch: 045, AUC: 0.9152, AP: 0.9280\n",
      "Epoch: 046, AUC: 0.9154, AP: 0.9283\n",
      "Epoch: 047, AUC: 0.9155, AP: 0.9284\n",
      "Epoch: 048, AUC: 0.9159, AP: 0.9288\n",
      "Epoch: 049, AUC: 0.9163, AP: 0.9294\n",
      "Epoch: 050, AUC: 0.9168, AP: 0.9300\n",
      "Epoch: 051, AUC: 0.9175, AP: 0.9307\n",
      "Epoch: 052, AUC: 0.9179, AP: 0.9312\n",
      "Epoch: 053, AUC: 0.9182, AP: 0.9316\n",
      "Epoch: 054, AUC: 0.9183, AP: 0.9317\n",
      "Epoch: 055, AUC: 0.9183, AP: 0.9320\n",
      "Epoch: 056, AUC: 0.9186, AP: 0.9322\n",
      "Epoch: 057, AUC: 0.9187, AP: 0.9322\n",
      "Epoch: 058, AUC: 0.9189, AP: 0.9324\n",
      "Epoch: 059, AUC: 0.9189, AP: 0.9324\n",
      "Epoch: 060, AUC: 0.9191, AP: 0.9325\n",
      "Epoch: 061, AUC: 0.9188, AP: 0.9324\n",
      "Epoch: 062, AUC: 0.9189, AP: 0.9325\n",
      "Epoch: 063, AUC: 0.9191, AP: 0.9328\n",
      "Epoch: 064, AUC: 0.9193, AP: 0.9329\n",
      "Epoch: 065, AUC: 0.9197, AP: 0.9332\n",
      "Epoch: 066, AUC: 0.9206, AP: 0.9339\n",
      "Epoch: 067, AUC: 0.9210, AP: 0.9341\n",
      "Epoch: 068, AUC: 0.9211, AP: 0.9343\n",
      "Epoch: 069, AUC: 0.9208, AP: 0.9341\n",
      "Epoch: 070, AUC: 0.9203, AP: 0.9339\n",
      "Epoch: 071, AUC: 0.9199, AP: 0.9338\n",
      "Epoch: 072, AUC: 0.9200, AP: 0.9339\n",
      "Epoch: 073, AUC: 0.9204, AP: 0.9342\n",
      "Epoch: 074, AUC: 0.9209, AP: 0.9344\n",
      "Epoch: 075, AUC: 0.9210, AP: 0.9344\n",
      "Epoch: 076, AUC: 0.9207, AP: 0.9341\n",
      "Epoch: 077, AUC: 0.9199, AP: 0.9336\n",
      "Epoch: 078, AUC: 0.9189, AP: 0.9329\n",
      "Epoch: 079, AUC: 0.9178, AP: 0.9325\n",
      "Epoch: 080, AUC: 0.9168, AP: 0.9320\n",
      "Epoch: 081, AUC: 0.9159, AP: 0.9316\n",
      "Epoch: 082, AUC: 0.9154, AP: 0.9314\n",
      "Epoch: 083, AUC: 0.9153, AP: 0.9314\n",
      "Epoch: 084, AUC: 0.9151, AP: 0.9314\n",
      "Epoch: 085, AUC: 0.9150, AP: 0.9315\n",
      "Epoch: 086, AUC: 0.9148, AP: 0.9315\n",
      "Epoch: 087, AUC: 0.9148, AP: 0.9318\n",
      "Epoch: 088, AUC: 0.9142, AP: 0.9315\n",
      "Epoch: 089, AUC: 0.9138, AP: 0.9314\n",
      "Epoch: 090, AUC: 0.9136, AP: 0.9314\n",
      "Epoch: 091, AUC: 0.9139, AP: 0.9317\n",
      "Epoch: 092, AUC: 0.9141, AP: 0.9319\n",
      "Epoch: 093, AUC: 0.9147, AP: 0.9325\n",
      "Epoch: 094, AUC: 0.9145, AP: 0.9325\n",
      "Epoch: 095, AUC: 0.9143, AP: 0.9327\n",
      "Epoch: 096, AUC: 0.9136, AP: 0.9325\n",
      "Epoch: 097, AUC: 0.9125, AP: 0.9319\n",
      "Epoch: 098, AUC: 0.9117, AP: 0.9313\n",
      "Epoch: 099, AUC: 0.9109, AP: 0.9307\n",
      "Epoch: 100, AUC: 0.9106, AP: 0.9303\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "    auc, ap = test(val_data.pos_edge_label_index, val_data.neg_edge_label_index)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    \n",
    "    writer.add_scalar('auc validation',auc,epoch) # nova linha\n",
    "    writer.add_scalar('ap validation',ap,epoch)   # nova linha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27390445",
   "metadata": {},
   "source": [
    "### Visualize as informações no TensorBoard\n",
    "Abra o terminal e digite: tensorboard --logdir=NOME DO SEU DIRETORIO ONDE SALVOU OS EXPERIMENTOS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
