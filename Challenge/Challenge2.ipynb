{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import community as community_louvain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product\n",
    "\n",
    "# allCategories = pd.read_csv(\"categories.csv\", index_col=0)\n",
    "\n",
    "class Feedforward(torch.nn.Module):\n",
    "    \n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Feedforward, self).__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "\n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "            self.fc3 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "            self.fc4 = torch.nn.Linear(self.hidden_size, 1)\n",
    "\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.out_act = torch.nn.Sigmoid()\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            output = self.fc1(x)\n",
    "            output = self.relu(output)\n",
    "\n",
    "            output = self.fc2(output)\n",
    "            output = self.relu(output)\n",
    "\n",
    "            output = self.fc3(output)\n",
    "            output = self.relu(output)\n",
    "\n",
    "            output = self.fc4(output)\n",
    "\n",
    "            output = self.out_act(output)\n",
    "\n",
    "            return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          idx                    edge  weight\n",
      "0      --DaPTJW3-tB1vP-PfdTEg  EL-iUP2pr6aJE2ZRVyNwyA       1\n",
      "1      --DaPTJW3-tB1vP-PfdTEg  MhiBpIBNTCAm1Xd3WzRzjQ       1\n",
      "2      --DaPTJW3-tB1vP-PfdTEg  dT70QOjn-o9pkdSAAPdSWQ       1\n",
      "3      --DaPTJW3-tB1vP-PfdTEg  mzREMIknfmagJugibXrCsQ       1\n",
      "4      --DaPTJW3-tB1vP-PfdTEg  zUgEycv_0a6hKu0nIkH1rA       1\n",
      "...                       ...                     ...     ...\n",
      "52985  zzUj3ej4vm_DtvRxNvWDEw  trzuDWvJqEIxtqjsKHCrhg       1\n",
      "52986  zzf3RkMI1Y2E1QaZqeU8yA  mZRKH9ngRY92bI_irrHq6w       1\n",
      "52987  zzf3RkMI1Y2E1QaZqeU8yA  s7Pj1mNYqRTGNOXLOiBafw       1\n",
      "52988  zzvlwkcNR1CCqOPXwuvz2A  4Jscimulh38Rq2hOgjb2Hg       1\n",
      "52989  zzvlwkcNR1CCqOPXwuvz2A  _xAJZOKBMPOe47p1MphB2w       1\n",
      "\n",
      "[52990 rows x 3 columns]\n",
      "RangeIndex(start=0, stop=52990, step=1)\n",
      "Index(['idx', 'edge', 'weight'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Network to evaluate links\n",
    "GMissingEdges = nx.read_gml(\"GraphMissingEdges.gml\")\n",
    "\n",
    "dfGraphEdges = pd.DataFrame.from_dict(dict(GMissingEdges.edges()), orient='index')\n",
    "dfGraphEdges = dfGraphEdges.reset_index()\n",
    "dfGraphEdges = dfGraphEdges.rename(columns={'level_0': 'idx', 'level_1':'edge'})\n",
    "\n",
    "print(dfGraphEdges)\n",
    "print(dfGraphEdges.index)\n",
    "print(dfGraphEdges.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        index  longitude   latitude stars reviewCount\n",
      "0      DHCdMpffUncZWxaiYNHSZw -79.434315  43.646220   4.0           4\n",
      "1      huCf4kwsoGl1YUHCjMJG5A -79.397848  43.631814   2.5           3\n",
      "2      a6FJ9HcERvtGF4PYILF_fA -79.378986  43.654590   2.5          63\n",
      "3      b8cwL5L3241tOcqXywEfLw -79.353691  43.683799   3.0           8\n",
      "4      YQ_z9iDgdNjwJhZ-owHSjA -79.396689  43.674244   2.5           7\n",
      "...                       ...        ...        ...   ...         ...\n",
      "11075  q3bkTWv854XTLXq1F4pnKg -79.409645  43.645954   4.0          61\n",
      "11076  8pGD3zt6HEL2xzaT3lqMFQ -79.408460  43.642893   4.5          12\n",
      "11077  iByQmTmTdO7hP4n1grSSWQ -79.422871  43.662417   4.0          37\n",
      "11078  lkM72Y21bjBqUGaW7iL7tQ -79.293509  43.803568   3.0          83\n",
      "11079  vUef2kuyYWG7phLySoRJGw -79.357862  43.676379   4.0          22\n",
      "\n",
      "[11080 rows x 5 columns]                           idx                    edge  weight\n",
      "0      --DaPTJW3-tB1vP-PfdTEg  EL-iUP2pr6aJE2ZRVyNwyA       1\n",
      "1      --DaPTJW3-tB1vP-PfdTEg  MhiBpIBNTCAm1Xd3WzRzjQ       1\n",
      "2      --DaPTJW3-tB1vP-PfdTEg  dT70QOjn-o9pkdSAAPdSWQ       1\n",
      "3      --DaPTJW3-tB1vP-PfdTEg  mzREMIknfmagJugibXrCsQ       1\n",
      "4      --DaPTJW3-tB1vP-PfdTEg  zUgEycv_0a6hKu0nIkH1rA       1\n",
      "...                       ...                     ...     ...\n",
      "52985  zzUj3ej4vm_DtvRxNvWDEw  trzuDWvJqEIxtqjsKHCrhg       1\n",
      "52986  zzf3RkMI1Y2E1QaZqeU8yA  mZRKH9ngRY92bI_irrHq6w       1\n",
      "52987  zzf3RkMI1Y2E1QaZqeU8yA  s7Pj1mNYqRTGNOXLOiBafw       1\n",
      "52988  zzvlwkcNR1CCqOPXwuvz2A  4Jscimulh38Rq2hOgjb2Hg       1\n",
      "52989  zzvlwkcNR1CCqOPXwuvz2A  _xAJZOKBMPOe47p1MphB2w       1\n",
      "\n",
      "[52990 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "GMissingEdges.nodes(data=True)\n",
    "# GMissingEdges.edges(data=True)\n",
    "\n",
    "# https://stackoverflow.com/questions/35046087/make-networkx-node-attributes-into-pandas-dataframe-columns\n",
    "dfGraphNodes = pd.DataFrame.from_dict(dict(GMissingEdges.nodes(data=True)), orient='index')\n",
    "dfGraphNodes.drop(['name','categories'],axis=1,inplace=True)\n",
    "\n",
    "# Calculate louvain communities\n",
    "# louvainPartition = community_louvain.best_partition(GMissingEdges)\n",
    "# dfLouvainPartition = pd.DataFrame.from_dict(louvainPartition, orient='index')\n",
    "# dfLouvainPartition = dfLouvainPartition.rename(columns={0: 'cluster'})\n",
    "\n",
    "# Add Louvain clusterization\n",
    "# dfGraphNodes = pd.concat([dfGraphNodes, dfLouvainPartition], axis=1)\n",
    "dfGraphNodes = dfGraphNodes.reset_index()\n",
    "\n",
    "print(dfGraphNodes, dfGraphEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        index  longitude   latitude stars reviewCount  \\\n",
      "0      --DaPTJW3-tB1vP-PfdTEg -79.444674  43.677807   3.5          49   \n",
      "1      --DaPTJW3-tB1vP-PfdTEg -79.444674  43.677807   3.5          49   \n",
      "2      --DaPTJW3-tB1vP-PfdTEg -79.444674  43.677807   3.5          49   \n",
      "3      --DaPTJW3-tB1vP-PfdTEg -79.444674  43.677807   3.5          49   \n",
      "4      --DaPTJW3-tB1vP-PfdTEg -79.444674  43.677807   3.5          49   \n",
      "...                       ...        ...        ...   ...         ...   \n",
      "52985  zzUj3ej4vm_DtvRxNvWDEw -79.402828  43.643715   3.0         114   \n",
      "52986  zzf3RkMI1Y2E1QaZqeU8yA -79.370983  43.651883   4.5          33   \n",
      "52987  zzf3RkMI1Y2E1QaZqeU8yA -79.370983  43.651883   4.5          33   \n",
      "52988  zzvlwkcNR1CCqOPXwuvz2A -79.393727  43.655822   3.5           7   \n",
      "52989  zzvlwkcNR1CCqOPXwuvz2A -79.393727  43.655822   3.5           7   \n",
      "\n",
      "                         edge  weight  \n",
      "0      EL-iUP2pr6aJE2ZRVyNwyA       1  \n",
      "1      MhiBpIBNTCAm1Xd3WzRzjQ       1  \n",
      "2      dT70QOjn-o9pkdSAAPdSWQ       1  \n",
      "3      mzREMIknfmagJugibXrCsQ       1  \n",
      "4      zUgEycv_0a6hKu0nIkH1rA       1  \n",
      "...                       ...     ...  \n",
      "52985  trzuDWvJqEIxtqjsKHCrhg       1  \n",
      "52986  mZRKH9ngRY92bI_irrHq6w       1  \n",
      "52987  s7Pj1mNYqRTGNOXLOiBafw       1  \n",
      "52988  4Jscimulh38Rq2hOgjb2Hg       1  \n",
      "52989  _xAJZOKBMPOe47p1MphB2w       1  \n",
      "\n",
      "[52990 rows x 7 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 52990 entries, 0 to 52989\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   index        52990 non-null  object \n",
      " 1   longitude    52990 non-null  float64\n",
      " 2   latitude     52990 non-null  float64\n",
      " 3   stars        52990 non-null  object \n",
      " 4   reviewCount  52990 non-null  object \n",
      " 5   edge         52990 non-null  object \n",
      " 6   weight       52990 non-null  int64  \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 3.2+ MB\n",
      "None\n",
      "Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\n",
      "                9,\n",
      "            ...\n",
      "            52980, 52981, 52982, 52983, 52984, 52985, 52986, 52987, 52988,\n",
      "            52989],\n",
      "           dtype='int64', length=52990)\n"
     ]
    }
   ],
   "source": [
    "dfGraph = pd.merge(dfGraphNodes, dfGraphEdges, how=\"right\", right_on=[\"idx\"], left_on=[\"index\"])\n",
    "dfGraph.drop(['idx'],axis=1,inplace=True)\n",
    "# dfGraph = dfGraph.set_index(\"index\")\n",
    "\n",
    "print(dfGraph)\n",
    "print(dfGraph.info())\n",
    "print(dfGraph.index)\n",
    "\n",
    "# dfGraph.to_csv(\"dfGraph.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         index                    edge  weight  longitude  \\\n",
      "0       klu0zF1rWAoNAhKPsFyUog  oQFMJqDwNXbNMRbcmIYRYg     0.0 -79.363541   \n",
      "1       klu0zF1rWAoNAhKPsFyUog  egLYFnycp8ktxMCvilFdLw     0.0 -79.363541   \n",
      "2       klu0zF1rWAoNAhKPsFyUog  Nxg73OigmRQQq0d1pKtkUQ     0.0 -79.363541   \n",
      "3       klu0zF1rWAoNAhKPsFyUog  hyXNS3tSmi6njhBjgo8eGw     0.0 -79.363541   \n",
      "4       klu0zF1rWAoNAhKPsFyUog  Sflaxtv6SR0lgbL7-pIGPQ     0.0 -79.363541   \n",
      "...                        ...                     ...     ...        ...   \n",
      "257159  zzUj3ej4vm_DtvRxNvWDEw  trzuDWvJqEIxtqjsKHCrhg     1.0 -79.402828   \n",
      "257160  zzf3RkMI1Y2E1QaZqeU8yA  mZRKH9ngRY92bI_irrHq6w     1.0 -79.370983   \n",
      "257161  zzf3RkMI1Y2E1QaZqeU8yA  s7Pj1mNYqRTGNOXLOiBafw     1.0 -79.370983   \n",
      "257162  zzvlwkcNR1CCqOPXwuvz2A  4Jscimulh38Rq2hOgjb2Hg     1.0 -79.393727   \n",
      "257163  zzvlwkcNR1CCqOPXwuvz2A  _xAJZOKBMPOe47p1MphB2w     1.0 -79.393727   \n",
      "\n",
      "         latitude stars reviewCount existEdge  \n",
      "0       43.709978   3.5         104     False  \n",
      "1       43.709978   3.5         104     False  \n",
      "2       43.709978   3.5         104     False  \n",
      "3       43.709978   3.5         104     False  \n",
      "4       43.709978   3.5         104     False  \n",
      "...           ...   ...         ...       ...  \n",
      "257159  43.643715   3.0         114      True  \n",
      "257160  43.651883   4.5          33      True  \n",
      "257161  43.651883   4.5          33      True  \n",
      "257162  43.655822   3.5           7      True  \n",
      "257163  43.655822   3.5           7      True  \n",
      "\n",
      "[257164 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "dfEdgesToEvaluate = pd.read_csv('edgesToEvaluate.csv')\n",
    "dfEdgesToEvaluate.drop(['linkID'], axis=1, inplace=True)\n",
    "dfEdgesToEvaluate.rename(columns={'venue1': 'index', 'venue2':'edge'},inplace=True)\n",
    "\n",
    "# Generate zero cases to help test\n",
    "combinedList = list(product(dfEdgesToEvaluate['index'], dfEdgesToEvaluate['edge']))\n",
    "# print(combinedList)\n",
    "\n",
    "dfT = pd.DataFrame(combinedList)\n",
    "dfT.rename(columns={0: 'index', 1:'edge'},inplace=True)\n",
    "\n",
    "dfGraph = pd.merge(dfT, dfGraph, how=\"outer\", on=[\"index\", \"edge\"])\n",
    "dfGraph.drop(['longitude','latitude','stars','reviewCount'], axis=1, inplace=True)\n",
    "\n",
    "# Remove edges to evaluate\n",
    "dfGraph = pd.concat([dfGraph, dfEdgesToEvaluate])\n",
    "dfGraph.drop_duplicates(subset=[\"index\",\"edge\"],keep=False, inplace=True)\n",
    "\n",
    "dfGraph = pd.merge(dfGraph, dfGraphNodes, how=\"inner\", on=\"index\")\n",
    "\n",
    "# weight = 0 and existEdge = False\n",
    "dfGraph['weight'] = dfGraph['weight'].fillna(0)\n",
    "dfGraph['existEdge'] = np.where((dfGraph.weight > 0 ), 'True', 'False')\n",
    "# print(dfGraph.info())\n",
    "print(dfGraph)\n",
    "\n",
    "dfGraph = dfGraph.astype({\"stars\": float, \"reviewCount\": int, \"existEdge\": bool})\n",
    "\n",
    "dfGraph.to_csv(\"resultTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>edge</th>\n",
       "      <th>weight</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>existEdge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>klu0zF1rWAoNAhKPsFyUog</td>\n",
       "      <td>oQFMJqDwNXbNMRbcmIYRYg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-79.363541</td>\n",
       "      <td>43.709978</td>\n",
       "      <td>3.5</td>\n",
       "      <td>104</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>klu0zF1rWAoNAhKPsFyUog</td>\n",
       "      <td>egLYFnycp8ktxMCvilFdLw</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-79.363541</td>\n",
       "      <td>43.709978</td>\n",
       "      <td>3.5</td>\n",
       "      <td>104</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>klu0zF1rWAoNAhKPsFyUog</td>\n",
       "      <td>Nxg73OigmRQQq0d1pKtkUQ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-79.363541</td>\n",
       "      <td>43.709978</td>\n",
       "      <td>3.5</td>\n",
       "      <td>104</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>klu0zF1rWAoNAhKPsFyUog</td>\n",
       "      <td>hyXNS3tSmi6njhBjgo8eGw</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-79.363541</td>\n",
       "      <td>43.709978</td>\n",
       "      <td>3.5</td>\n",
       "      <td>104</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>klu0zF1rWAoNAhKPsFyUog</td>\n",
       "      <td>Sflaxtv6SR0lgbL7-pIGPQ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-79.363541</td>\n",
       "      <td>43.709978</td>\n",
       "      <td>3.5</td>\n",
       "      <td>104</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257159</th>\n",
       "      <td>zzUj3ej4vm_DtvRxNvWDEw</td>\n",
       "      <td>trzuDWvJqEIxtqjsKHCrhg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-79.402828</td>\n",
       "      <td>43.643715</td>\n",
       "      <td>3.0</td>\n",
       "      <td>114</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257160</th>\n",
       "      <td>zzf3RkMI1Y2E1QaZqeU8yA</td>\n",
       "      <td>mZRKH9ngRY92bI_irrHq6w</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-79.370983</td>\n",
       "      <td>43.651883</td>\n",
       "      <td>4.5</td>\n",
       "      <td>33</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257161</th>\n",
       "      <td>zzf3RkMI1Y2E1QaZqeU8yA</td>\n",
       "      <td>s7Pj1mNYqRTGNOXLOiBafw</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-79.370983</td>\n",
       "      <td>43.651883</td>\n",
       "      <td>4.5</td>\n",
       "      <td>33</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257162</th>\n",
       "      <td>zzvlwkcNR1CCqOPXwuvz2A</td>\n",
       "      <td>4Jscimulh38Rq2hOgjb2Hg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-79.393727</td>\n",
       "      <td>43.655822</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257163</th>\n",
       "      <td>zzvlwkcNR1CCqOPXwuvz2A</td>\n",
       "      <td>_xAJZOKBMPOe47p1MphB2w</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-79.393727</td>\n",
       "      <td>43.655822</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257164 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         index                    edge  weight  longitude  \\\n",
       "0       klu0zF1rWAoNAhKPsFyUog  oQFMJqDwNXbNMRbcmIYRYg     0.0 -79.363541   \n",
       "1       klu0zF1rWAoNAhKPsFyUog  egLYFnycp8ktxMCvilFdLw     0.0 -79.363541   \n",
       "2       klu0zF1rWAoNAhKPsFyUog  Nxg73OigmRQQq0d1pKtkUQ     0.0 -79.363541   \n",
       "3       klu0zF1rWAoNAhKPsFyUog  hyXNS3tSmi6njhBjgo8eGw     0.0 -79.363541   \n",
       "4       klu0zF1rWAoNAhKPsFyUog  Sflaxtv6SR0lgbL7-pIGPQ     0.0 -79.363541   \n",
       "...                        ...                     ...     ...        ...   \n",
       "257159  zzUj3ej4vm_DtvRxNvWDEw  trzuDWvJqEIxtqjsKHCrhg     1.0 -79.402828   \n",
       "257160  zzf3RkMI1Y2E1QaZqeU8yA  mZRKH9ngRY92bI_irrHq6w     1.0 -79.370983   \n",
       "257161  zzf3RkMI1Y2E1QaZqeU8yA  s7Pj1mNYqRTGNOXLOiBafw     1.0 -79.370983   \n",
       "257162  zzvlwkcNR1CCqOPXwuvz2A  4Jscimulh38Rq2hOgjb2Hg     1.0 -79.393727   \n",
       "257163  zzvlwkcNR1CCqOPXwuvz2A  _xAJZOKBMPOe47p1MphB2w     1.0 -79.393727   \n",
       "\n",
       "         latitude  stars  reviewCount  existEdge  \n",
       "0       43.709978    3.5          104       True  \n",
       "1       43.709978    3.5          104       True  \n",
       "2       43.709978    3.5          104       True  \n",
       "3       43.709978    3.5          104       True  \n",
       "4       43.709978    3.5          104       True  \n",
       "...           ...    ...          ...        ...  \n",
       "257159  43.643715    3.0          114       True  \n",
       "257160  43.651883    4.5           33       True  \n",
       "257161  43.651883    4.5           33       True  \n",
       "257162  43.655822    3.5            7       True  \n",
       "257163  43.655822    3.5            7       True  \n",
       "\n",
       "[257164 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace place ids to integers ids\n",
    "placesId = dfGraphNodes['index'].to_dict()\n",
    "# print(placesId)\n",
    "\n",
    "# for index,place in placesId.items():\n",
    "#     dfGraph.replace({'index':{place:index}},inplace=True)\n",
    "#     dfGraph.replace({'edge':{place:index}},inplace=True)\n",
    "\n",
    "dfGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n",
      "torch.Size([257164])\n",
      "torch.Size([257164, 3])\n",
      "Training data:\n",
      "torch.Size([205731, 3])\n",
      "torch.Size([205731])\n",
      "Test data:\n",
      "torch.Size([51433, 3])\n",
      "torch.Size([51433])\n"
     ]
    }
   ],
   "source": [
    "# Generate data without edges to help in test cases\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = 'cpu'\n",
    "print(\"Using {}\".format(device))\n",
    "\n",
    "focus = dfGraph['existEdge']\n",
    "data = dfGraph.iloc[:,3:6]\n",
    "# data = data.astype({\"stars\": float, \"reviewCount\": int})\n",
    "\n",
    "# print(focus)\n",
    "# print(data.info())\n",
    "# print(dfGraph.columns)\n",
    "\n",
    "Y_tensor = torch.tensor(focus)\n",
    "X_tensor = torch.tensor(data.to_numpy())\n",
    "print(Y_tensor.shape)\n",
    "print(X_tensor.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, Y_tensor, test_size = 0.20, random_state=5)\n",
    "\n",
    "print(\"Training data:\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"Test data:\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Cast fields to float to avoid compatibility problems\n",
    "X_train = X_train.float().to(device)\n",
    "y_train = y_train.float().to(device)\n",
    "X_test = X_test.float().to(device)\n",
    "y_test = y_test.float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features: 3\n",
      "Feedforward(\n",
      "  (fc1): Linear(in_features=3, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (fc4): Linear(in_features=20, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (out_act): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#input = 8 (número de features), e hidden size = 20 (número de neurôneos na camada escondida)\n",
    "num_features = X_train.shape[1]\n",
    "print(\"num_features: \"+str(num_features))\n",
    "\n",
    "model = Feedforward(num_features, 20).to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# lr = Learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willdoliver/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([51433])) that is different to the input size (torch.Size([51433, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste - perda antes do treinamento 0.03223619610071182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willdoliver/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([205731])) that is different to the input size (torch.Size([205731, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:68] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 169300977444 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7e863a16ad00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {}: perda treino: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3111\u001b[0m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3112\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:68] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 169300977444 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred = model(X_test)\n",
    "before_train = criterion(y_pred, y_test) \n",
    "print('Teste - perda antes do treinamento' , before_train.item())\n",
    "\n",
    "model.train()\n",
    "epoch = 50\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    y_pred = model(X_train)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    print('Epoch {}: perda treino: {}'.format(epoch, loss.item()))\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # update pass\n",
    "    optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "y_pred = model(X_test)\n",
    "after_train = criterion(y_pred, y_test)\n",
    "print('Teste - perda depois do treinamento' , after_train.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(X_test)\n",
    "print(y_pred)\n",
    "print(after_train)\n",
    "\n",
    "#Links to be evaluated\n",
    "dfEdgesToEvaluate = pd.read_csv('edgesToEvaluate.csv')\n",
    "dfEdgesToEvaluate = dfEdgesToEvaluate.rename(columns={'venue1': 'index', 'venue2':'edge'})\n",
    "dfEdgesToEvaluate.set_index('index',inplace=True)\n",
    "\n",
    "# print(dfEdgesToEvaluate)\n",
    "dfNodesToCopy = dfGraphNodes.copy()\n",
    "dfNodesToCopy.set_index('index',inplace=True)\n",
    "# print(dfNodesToCopy)\n",
    "\n",
    "dfToTest = pd.merge(dfEdgesToEvaluate, dfNodesToCopy, on='index')\n",
    "dfToTest.reset_index(inplace=True)\n",
    "dfToTest.drop('linkID',axis=1,inplace=True)\n",
    "\n",
    "for index,place in placesId.items():\n",
    "    dfToTest.replace({'index':{place:index}},inplace=True)\n",
    "    dfToTest.replace({'edge':{place:index}},inplace=True)\n",
    "\n",
    "dfToTest['weight'] = 0\n",
    "\n",
    "dfToTest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus = dfToTest['existEdge']\n",
    "# Same column order\n",
    "data = dfToTest.iloc[:,2:6]\n",
    "data = data.astype({\"stars\": float, \"reviewCount\": int})\n",
    "\n",
    "# print(focus)\n",
    "# print(data.info())\n",
    "# print(dfGraph.columns)\n",
    "\n",
    "Y_tensor_eval = torch.zeros(500,1)\n",
    "X_tensor_eval = torch.tensor(data.to_numpy())\n",
    "print(Y_tensor.shape)\n",
    "print(X_tensor.shape)\n",
    "\n",
    "# X_train_eval, X_test_eval, y_train_eval, y_test_eval = train_test_split(X_tensor_eval, Y_tensor_eval, test_size = 0.9, random_state=5)\n",
    "\n",
    "print(\"Training data:\")\n",
    "# print(X_train_eval.shape)\n",
    "# print(y_train_eval.shape)\n",
    "\n",
    "print(\"Test data:\")\n",
    "print(X_tensor_eval.shape)\n",
    "# print(y_test_eval.shape)\n",
    "\n",
    "# Cast fields to float to avoid compatibility problems\n",
    "# X_train_eval = X_train_eval.float().to(device)\n",
    "# y_train_eval = y_train_eval.float().to(device)\n",
    "X_tensor_eval = X_tensor_eval.float().to(device)\n",
    "Y_tensor_eval = Y_tensor_eval.float().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_pred = model(X_tensor_eval)\n",
    "after_train = criterion(y_pred, Y_tensor_eval) \n",
    "print('Teste - usando dados do treinamento' , after_train.item())\n",
    "\n",
    "# print(len(y_pred))\n",
    "# print(y_pred)\n",
    "\n",
    "exitData = y_pred.detach().numpy()\n",
    "print(len(exitData))\n",
    "print(exitData)\n",
    "\n",
    "binaryExit = np.where(exitData > 0.1, 1, 0)\n",
    "print(len(binaryExit))\n",
    "print(binaryExit)\n",
    "dfEdgesToEvaluate['link'] = binaryExit\n",
    "\n",
    "# dfEdgesToEvaluate.set_index('linkID',inplace=True)\n",
    "dfEdgesToEvaluate.drop(['edge'],axis=1,inplace=True,errors='ignore')\n",
    "\n",
    "dfEdgesToEvaluate.to_csv(\"edgesToEvaluateAnswers.csv\", columns=['linkID','link'],index=False) \n",
    "dfEdgesToEvaluate\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
