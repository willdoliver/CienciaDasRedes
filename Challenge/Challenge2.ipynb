{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd4cba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import community as community_louvain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product\n",
    "\n",
    "# allCategories = pd.read_csv(\"categories.csv\", index_col=0)\n",
    "\n",
    "class Feedforward(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Feedforward, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size  = hidden_size\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.fc2 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.fc3 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.fc4 = torch.nn.Linear(self.hidden_size, 1)\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.out_act = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.fc1(x)\n",
    "        output = self.relu(output)\n",
    "\n",
    "        output = self.fc2(output)\n",
    "        output = self.relu(output)\n",
    "\n",
    "        output = self.fc3(output)\n",
    "        output = self.relu(output)\n",
    "\n",
    "        output = self.fc4(output)\n",
    "        output = self.out_act(output)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "360e229f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          idx                    edge  weight\n",
      "0      --DaPTJW3-tB1vP-PfdTEg  EL-iUP2pr6aJE2ZRVyNwyA       1\n",
      "1      --DaPTJW3-tB1vP-PfdTEg  MhiBpIBNTCAm1Xd3WzRzjQ       1\n",
      "2      --DaPTJW3-tB1vP-PfdTEg  dT70QOjn-o9pkdSAAPdSWQ       1\n",
      "3      --SrzpvFLwP_YFwB_Cetow  4PINzgssH9dDbw36jofi_Q       1\n",
      "4      --SrzpvFLwP_YFwB_Cetow  9FPs1mXHZEoEWo3kw9cwGQ       1\n",
      "...                       ...                     ...     ...\n",
      "42387  zzUj3ej4vm_DtvRxNvWDEw  tJcpzXzykNSLuzWwa1JQUw       1\n",
      "42388  zzUj3ej4vm_DtvRxNvWDEw  trzuDWvJqEIxtqjsKHCrhg       1\n",
      "42389  zzf3RkMI1Y2E1QaZqeU8yA  mZRKH9ngRY92bI_irrHq6w       1\n",
      "42390  zzvlwkcNR1CCqOPXwuvz2A  4Jscimulh38Rq2hOgjb2Hg       1\n",
      "42391  zzvlwkcNR1CCqOPXwuvz2A  _xAJZOKBMPOe47p1MphB2w       1\n",
      "\n",
      "[42392 rows x 3 columns]\n",
      "RangeIndex(start=0, stop=42392, step=1)\n",
      "Index(['idx', 'edge', 'weight'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Network to evaluate links\n",
    "GMissingEdges = nx.read_gml(\"GraphMissingEdges.gml\")\n",
    "\n",
    "# To local test -----------------------------------------\n",
    "# Remove 20% das arestas\n",
    "proportion_edges = 0.2\n",
    "edge_subset = random.sample(GMissingEdges.edges(), int(proportion_edges * GMissingEdges.number_of_edges()))\n",
    "\n",
    "# Cria uma cópia do grafo e remove arestas\n",
    "GMissingEdgesTrain = GMissingEdges.copy()\n",
    "GMissingEdgesTrain.remove_edges_from(edge_subset)\n",
    "# print(edge_subset)\n",
    "# To local test -----------------------------------------\n",
    "\n",
    "dfGraphEdges = pd.DataFrame.from_dict(dict(GMissingEdgesTrain.edges()), orient='index')\n",
    "dfGraphEdges = dfGraphEdges.reset_index()\n",
    "# Renomeia campos como index e edge, em comparação aos nós que estão conectados\n",
    "dfGraphEdges = dfGraphEdges.rename(columns={'level_0': 'idx', 'level_1':'edge'})\n",
    "\n",
    "print(dfGraphEdges)\n",
    "print(dfGraphEdges.index)\n",
    "print(dfGraphEdges.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7128adcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venue1</th>\n",
       "      <th>venue2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jniApOOS8ppUHhESL7OzTg</td>\n",
       "      <td>KYYUvIJi7laFzK1NsaE77Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gyFYZV4b_9TxG1ulQNi0Ig</td>\n",
       "      <td>SJr6Hs_XS4ubUq8NojqXzA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KVUOj74lBgogrdKcNQH_zQ</td>\n",
       "      <td>0sPOBQHlVvuhO1h-1p1ccQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3HwoIoJcV7yDi3RV7T-oDQ</td>\n",
       "      <td>czzjfPe7kO9VxoYV9l-fxA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84JCu-4LvE6SDAglrJztGA</td>\n",
       "      <td>pTbkdBDDKxNVjKUZ_6RAug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10593</th>\n",
       "      <td>Pz13Ru_-U4qoZiu89ezVmQ</td>\n",
       "      <td>JOoblYsQjFT-47tkt6om0A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10594</th>\n",
       "      <td>e41TP5cXZqSrz50xCBJqZw</td>\n",
       "      <td>MzEH3h8meWt7fW146U7y0g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10595</th>\n",
       "      <td>PyIF7dcDPNpfmi8ks-sKOQ</td>\n",
       "      <td>GxzEsd-81hVP6C2h6wMvBw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10596</th>\n",
       "      <td>_T8qy9XAKAFLJdmoLg1Q-g</td>\n",
       "      <td>QePLHlU8MFaU2Sf9dzoLTg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10597</th>\n",
       "      <td>fy6srT4KpbE7ICBLdypEuQ</td>\n",
       "      <td>2PCz_uVX7GOXtGHNXAPXhw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10598 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       venue1                  venue2\n",
       "0      jniApOOS8ppUHhESL7OzTg  KYYUvIJi7laFzK1NsaE77Q\n",
       "1      gyFYZV4b_9TxG1ulQNi0Ig  SJr6Hs_XS4ubUq8NojqXzA\n",
       "2      KVUOj74lBgogrdKcNQH_zQ  0sPOBQHlVvuhO1h-1p1ccQ\n",
       "3      3HwoIoJcV7yDi3RV7T-oDQ  czzjfPe7kO9VxoYV9l-fxA\n",
       "4      84JCu-4LvE6SDAglrJztGA  pTbkdBDDKxNVjKUZ_6RAug\n",
       "...                       ...                     ...\n",
       "10593  Pz13Ru_-U4qoZiu89ezVmQ  JOoblYsQjFT-47tkt6om0A\n",
       "10594  e41TP5cXZqSrz50xCBJqZw  MzEH3h8meWt7fW146U7y0g\n",
       "10595  PyIF7dcDPNpfmi8ks-sKOQ  GxzEsd-81hVP6C2h6wMvBw\n",
       "10596  _T8qy9XAKAFLJdmoLg1Q-g  QePLHlU8MFaU2Sf9dzoLTg\n",
       "10597  fy6srT4KpbE7ICBLdypEuQ  2PCz_uVX7GOXtGHNXAPXhw\n",
       "\n",
       "[10598 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create test file using data removed\n",
    "dfToEvaluate = pd.DataFrame(edge_subset)\n",
    "dfToEvaluate = dfToEvaluate.rename(columns={0:'venue1',1:'venue2'})\n",
    "dfToEvaluate.to_csv(\"edgesToEvaluateTest.csv\", index_label='linkID')\n",
    "dfToEvaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb434446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        index  longitude   latitude stars reviewCount  cluster\n",
      "0      DHCdMpffUncZWxaiYNHSZw -79.434315  43.646220   4.0           4        0\n",
      "1      huCf4kwsoGl1YUHCjMJG5A -79.397848  43.631814   2.5           3        1\n",
      "2      a6FJ9HcERvtGF4PYILF_fA -79.378986  43.654590   2.5          63        2\n",
      "3      b8cwL5L3241tOcqXywEfLw -79.353691  43.683799   3.0           8        3\n",
      "4      YQ_z9iDgdNjwJhZ-owHSjA -79.396689  43.674244   2.5           7        2\n",
      "...                       ...        ...        ...   ...         ...      ...\n",
      "11075  q3bkTWv854XTLXq1F4pnKg -79.409645  43.645954   4.0          61        7\n",
      "11076  8pGD3zt6HEL2xzaT3lqMFQ -79.408460  43.642893   4.5          12        2\n",
      "11077  iByQmTmTdO7hP4n1grSSWQ -79.422871  43.662417   4.0          37        2\n",
      "11078  lkM72Y21bjBqUGaW7iL7tQ -79.293509  43.803568   3.0          83        5\n",
      "11079  vUef2kuyYWG7phLySoRJGw -79.357862  43.676379   4.0          22      109\n",
      "\n",
      "[11080 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "GMissingEdges.nodes(data=True)\n",
    "# GMissingEdges.edges(data=True)\n",
    "\n",
    "dfGraphNodes = pd.DataFrame.from_dict(dict(GMissingEdgesTrain.nodes(data=True)), orient='index')\n",
    "dfGraphNodes.drop(['name','categories'],axis=1,inplace=True)\n",
    "\n",
    "# Calculate louvain communities\n",
    "louvainPartition = community_louvain.best_partition(GMissingEdges)\n",
    "dfLouvainPartition = pd.DataFrame.from_dict(louvainPartition, orient='index')\n",
    "dfLouvainPartition = dfLouvainPartition.rename(columns={0: 'cluster'})\n",
    "\n",
    "# Add Louvain clusterization\n",
    "dfGraphNodes = pd.concat([dfGraphNodes, dfLouvainPartition], axis=1)\n",
    "dfGraphNodes = dfGraphNodes.reset_index()\n",
    "\n",
    "# print(dfGraphNodes, dfGraphEdges)\n",
    "print(dfGraphNodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e6f981",
   "metadata": {},
   "source": [
    "A princípio tinha removido as colunas 'name' e 'categories', pois iria utilizar o atributo da aresta (weight) para tentar prever os links faltantes.\n",
    "Foi adicionado a clusterização de Louvain para tentar mais assertividade nos possíveis links, após esse cálculo a informação foi agregada aos atributos dos nós."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a12e464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        index  longitude   latitude stars reviewCount  \\\n",
      "0      --DaPTJW3-tB1vP-PfdTEg -79.444674  43.677807   3.5          49   \n",
      "1      --DaPTJW3-tB1vP-PfdTEg -79.444674  43.677807   3.5          49   \n",
      "2      --DaPTJW3-tB1vP-PfdTEg -79.444674  43.677807   3.5          49   \n",
      "3      --SrzpvFLwP_YFwB_Cetow -79.288858  43.806750   3.5          43   \n",
      "4      --SrzpvFLwP_YFwB_Cetow -79.288858  43.806750   3.5          43   \n",
      "...                       ...        ...        ...   ...         ...   \n",
      "42387  zzUj3ej4vm_DtvRxNvWDEw -79.402828  43.643715   3.0         114   \n",
      "42388  zzUj3ej4vm_DtvRxNvWDEw -79.402828  43.643715   3.0         114   \n",
      "42389  zzf3RkMI1Y2E1QaZqeU8yA -79.370983  43.651883   4.5          33   \n",
      "42390  zzvlwkcNR1CCqOPXwuvz2A -79.393727  43.655822   3.5           7   \n",
      "42391  zzvlwkcNR1CCqOPXwuvz2A -79.393727  43.655822   3.5           7   \n",
      "\n",
      "       cluster                    edge  weight  \n",
      "0            2  EL-iUP2pr6aJE2ZRVyNwyA       1  \n",
      "1            2  MhiBpIBNTCAm1Xd3WzRzjQ       1  \n",
      "2            2  dT70QOjn-o9pkdSAAPdSWQ       1  \n",
      "3            7  4PINzgssH9dDbw36jofi_Q       1  \n",
      "4            7  9FPs1mXHZEoEWo3kw9cwGQ       1  \n",
      "...        ...                     ...     ...  \n",
      "42387        4  tJcpzXzykNSLuzWwa1JQUw       1  \n",
      "42388        4  trzuDWvJqEIxtqjsKHCrhg       1  \n",
      "42389        7  mZRKH9ngRY92bI_irrHq6w       1  \n",
      "42390        5  4Jscimulh38Rq2hOgjb2Hg       1  \n",
      "42391        5  _xAJZOKBMPOe47p1MphB2w       1  \n",
      "\n",
      "[42392 rows x 8 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 42392 entries, 0 to 42391\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   index        42392 non-null  object \n",
      " 1   longitude    42392 non-null  float64\n",
      " 2   latitude     42392 non-null  float64\n",
      " 3   stars        42392 non-null  object \n",
      " 4   reviewCount  42392 non-null  object \n",
      " 5   cluster      42392 non-null  int64  \n",
      " 6   edge         42392 non-null  object \n",
      " 7   weight       42392 non-null  int64  \n",
      "dtypes: float64(2), int64(2), object(4)\n",
      "memory usage: 2.9+ MB\n",
      "None\n",
      "Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\n",
      "                9,\n",
      "            ...\n",
      "            42382, 42383, 42384, 42385, 42386, 42387, 42388, 42389, 42390,\n",
      "            42391],\n",
      "           dtype='int64', length=42392)\n"
     ]
    }
   ],
   "source": [
    "dfGraph = pd.merge(dfGraphNodes, dfGraphEdges, how=\"right\", right_on=[\"idx\"], left_on=[\"index\"])\n",
    "dfGraph.drop(['idx'],axis=1,inplace=True)\n",
    "# dfGraph = dfGraph.set_index(\"index\")\n",
    "\n",
    "print(dfGraph)\n",
    "print(dfGraph.info())\n",
    "print(dfGraph.index)\n",
    "\n",
    "# dfGraph.to_csv(\"dfGraph.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11bfe75",
   "metadata": {},
   "source": [
    "Aqui os dataframes de arestas e nós foram mergeados, para capturar os dados de origem-destino da aresta juntamente com os atributos dos nós"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a26f38af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         index                    edge  weight  longitude  \\\n",
      "0       klu0zF1rWAoNAhKPsFyUog  oQFMJqDwNXbNMRbcmIYRYg     0.0 -79.363541   \n",
      "1       klu0zF1rWAoNAhKPsFyUog  egLYFnycp8ktxMCvilFdLw     0.0 -79.363541   \n",
      "2       klu0zF1rWAoNAhKPsFyUog  Nxg73OigmRQQq0d1pKtkUQ     0.0 -79.363541   \n",
      "3       klu0zF1rWAoNAhKPsFyUog  hyXNS3tSmi6njhBjgo8eGw     0.0 -79.363541   \n",
      "4       klu0zF1rWAoNAhKPsFyUog  Sflaxtv6SR0lgbL7-pIGPQ     0.0 -79.363541   \n",
      "...                        ...                     ...     ...        ...   \n",
      "246770  zzUj3ej4vm_DtvRxNvWDEw  tJcpzXzykNSLuzWwa1JQUw     1.0 -79.402828   \n",
      "246771  zzUj3ej4vm_DtvRxNvWDEw  trzuDWvJqEIxtqjsKHCrhg     1.0 -79.402828   \n",
      "246772  zzf3RkMI1Y2E1QaZqeU8yA  mZRKH9ngRY92bI_irrHq6w     1.0 -79.370983   \n",
      "246773  zzvlwkcNR1CCqOPXwuvz2A  4Jscimulh38Rq2hOgjb2Hg     1.0 -79.393727   \n",
      "246774  zzvlwkcNR1CCqOPXwuvz2A  _xAJZOKBMPOe47p1MphB2w     1.0 -79.393727   \n",
      "\n",
      "         latitude stars reviewCount  cluster existEdge  \n",
      "0       43.709978   3.5         104        2     False  \n",
      "1       43.709978   3.5         104        2     False  \n",
      "2       43.709978   3.5         104        2     False  \n",
      "3       43.709978   3.5         104        2     False  \n",
      "4       43.709978   3.5         104        2     False  \n",
      "...           ...   ...         ...      ...       ...  \n",
      "246770  43.643715   3.0         114        4      True  \n",
      "246771  43.643715   3.0         114        4      True  \n",
      "246772  43.651883   4.5          33        7      True  \n",
      "246773  43.655822   3.5           7        5      True  \n",
      "246774  43.655822   3.5           7        5      True  \n",
      "\n",
      "[246775 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "dfEdgesToEvaluate = pd.read_csv('edgesToEvaluate.csv')\n",
    "dfEdgesToEvaluate.drop(['linkID'], axis=1, inplace=True)\n",
    "dfEdgesToEvaluate.rename(columns={'venue1': 'index', 'venue2':'edge'},inplace=True)\n",
    "\n",
    "# Generate zero cases to help test\n",
    "combinedList = list(product(dfEdgesToEvaluate['index'], dfEdgesToEvaluate['edge']))\n",
    "# print(combinedList)\n",
    "\n",
    "dfT = pd.DataFrame(combinedList)\n",
    "dfT.rename(columns={0: 'index', 1:'edge'},inplace=True)\n",
    "\n",
    "dfGraph = pd.merge(dfT, dfGraph, how=\"outer\", on=[\"index\", \"edge\"])\n",
    "dfGraph.drop(['longitude','latitude','stars','reviewCount','cluster', 'categories', 'name'], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "# Remove edges to evaluate\n",
    "dfGraph = pd.concat([dfGraph, dfEdgesToEvaluate])\n",
    "dfGraph.drop_duplicates(subset=[\"index\",\"edge\"],keep=False, inplace=True)\n",
    "\n",
    "dfGraph = pd.merge(dfGraph, dfGraphNodes, how=\"inner\", on=\"index\")\n",
    "\n",
    "# weight = 0 and existEdge = False for created cases\n",
    "dfGraph['weight'] = dfGraph['weight'].fillna(0)\n",
    "dfGraph['existEdge'] = np.where((dfGraph.weight > 0 ), 'True', 'False')\n",
    "# print(dfGraph.info())\n",
    "print(dfGraph)\n",
    "\n",
    "dfGraph = dfGraph.astype({\"stars\": float, \"reviewCount\": int, \"existEdge\": bool})\n",
    "\n",
    "dfGraph.to_csv(\"resultTest.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277f0110",
   "metadata": {},
   "source": [
    "Para incrementar mais os dados para treinamento, inclui algumas combinações de nós que não possuiam arestas para treinar também casos falsos em que não há arestas entre os nós, e na sequência para o dataset não ficar muito grande, foram deletadas várias arestas para voltar ao tamanho normal, pois o processamento estava inviável.\n",
    "Foi criado o campo para predição das arestas chamado 'existEdge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e692587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataframe before deletion: 246775\n",
      "Elements deleted 197420\n",
      "Size of dataframe after deletion: 49355\n",
      "                        index                    edge  weight  longitude  \\\n",
      "0      klu0zF1rWAoNAhKPsFyUog  oQFMJqDwNXbNMRbcmIYRYg     0.0 -79.363541   \n",
      "1      klu0zF1rWAoNAhKPsFyUog  egLYFnycp8ktxMCvilFdLw     0.0 -79.363541   \n",
      "2      klu0zF1rWAoNAhKPsFyUog  Nxg73OigmRQQq0d1pKtkUQ     0.0 -79.363541   \n",
      "3      klu0zF1rWAoNAhKPsFyUog  pdTYUCGkYz35utxPyUMoag     0.0 -79.363541   \n",
      "4      klu0zF1rWAoNAhKPsFyUog  78Hx8KRI2SVKB-OibvEoag     0.0 -79.363541   \n",
      "...                       ...                     ...     ...        ...   \n",
      "49350  zwhgnF9ICofzzIAIuWtbkQ  bCc7Fi46nrgZHhx9f5gIGg     1.0 -79.456523   \n",
      "49351  zy_NHTqtfSrfTGGPoqy4Mw  zNL9Ajmn3gHUk__kpX7aIg     1.0 -79.448091   \n",
      "49352  zzUj3ej4vm_DtvRxNvWDEw  eSp5ge9VAwTywZKlJ_LBvA     1.0 -79.402828   \n",
      "49353  zzUj3ej4vm_DtvRxNvWDEw  o1FLiGssn5Wxc_POWSuZZA     1.0 -79.402828   \n",
      "49354  zzUj3ej4vm_DtvRxNvWDEw  tJcpzXzykNSLuzWwa1JQUw     1.0 -79.402828   \n",
      "\n",
      "        latitude  stars  reviewCount  cluster  existEdge  \n",
      "0      43.709978    3.5          104        2       True  \n",
      "1      43.709978    3.5          104        2       True  \n",
      "2      43.709978    3.5          104        2       True  \n",
      "3      43.709978    3.5          104        2       True  \n",
      "4      43.709978    3.5          104        2       True  \n",
      "...          ...    ...          ...      ...        ...  \n",
      "49350  43.670462    3.5           10        2       True  \n",
      "49351  43.644215    3.5           24       58       True  \n",
      "49352  43.643715    3.0          114        4       True  \n",
      "49353  43.643715    3.0          114        4       True  \n",
      "49354  43.643715    3.0          114        4       True  \n",
      "\n",
      "[49355 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Delete random ids because the structure is too heavy\n",
    "print(\"Size of dataframe before deletion: %s\" % (len(dfGraph)))\n",
    "delSize = int(len(dfGraph)*0.8) # Come back to original size of dataframe +-\n",
    "\n",
    "deletedItems = random.sample(range(len(dfGraph)), delSize)\n",
    "\n",
    "dfGraph.drop(dfGraph.index[deletedItems], inplace=True)\n",
    "\n",
    "print(\"Elements deleted %s\" % (delSize))\n",
    "print(\"Size of dataframe after deletion: %s\" % (len(dfGraph)))\n",
    "\n",
    "dfGraph = dfGraph.reset_index()\n",
    "dfGraph.drop('level_0',axis=1,inplace=True)\n",
    "# print (deletedItems)\n",
    "print(dfGraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2ab0edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>edge</th>\n",
       "      <th>weight</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>cluster</th>\n",
       "      <th>existEdge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2920</td>\n",
       "      <td>6729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-79.363541</td>\n",
       "      <td>43.709978</td>\n",
       "      <td>3.5</td>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2920</td>\n",
       "      <td>6183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-79.363541</td>\n",
       "      <td>43.709978</td>\n",
       "      <td>3.5</td>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2920</td>\n",
       "      <td>4031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-79.363541</td>\n",
       "      <td>43.709978</td>\n",
       "      <td>3.5</td>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2920</td>\n",
       "      <td>9893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-79.363541</td>\n",
       "      <td>43.709978</td>\n",
       "      <td>3.5</td>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2920</td>\n",
       "      <td>5752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-79.363541</td>\n",
       "      <td>43.709978</td>\n",
       "      <td>3.5</td>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49350</th>\n",
       "      <td>2917</td>\n",
       "      <td>5852</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-79.456523</td>\n",
       "      <td>43.670462</td>\n",
       "      <td>3.5</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49351</th>\n",
       "      <td>2169</td>\n",
       "      <td>8515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-79.448091</td>\n",
       "      <td>43.644215</td>\n",
       "      <td>3.5</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49352</th>\n",
       "      <td>175</td>\n",
       "      <td>9088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-79.402828</td>\n",
       "      <td>43.643715</td>\n",
       "      <td>3.0</td>\n",
       "      <td>114</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49353</th>\n",
       "      <td>175</td>\n",
       "      <td>230</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-79.402828</td>\n",
       "      <td>43.643715</td>\n",
       "      <td>3.0</td>\n",
       "      <td>114</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49354</th>\n",
       "      <td>175</td>\n",
       "      <td>349</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-79.402828</td>\n",
       "      <td>43.643715</td>\n",
       "      <td>3.0</td>\n",
       "      <td>114</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49355 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  edge  weight  longitude   latitude  stars  reviewCount  cluster  \\\n",
       "0       2920  6729     0.0 -79.363541  43.709978    3.5          104        2   \n",
       "1       2920  6183     0.0 -79.363541  43.709978    3.5          104        2   \n",
       "2       2920  4031     0.0 -79.363541  43.709978    3.5          104        2   \n",
       "3       2920  9893     0.0 -79.363541  43.709978    3.5          104        2   \n",
       "4       2920  5752     0.0 -79.363541  43.709978    3.5          104        2   \n",
       "...      ...   ...     ...        ...        ...    ...          ...      ...   \n",
       "49350   2917  5852     1.0 -79.456523  43.670462    3.5           10        2   \n",
       "49351   2169  8515     1.0 -79.448091  43.644215    3.5           24       58   \n",
       "49352    175  9088     1.0 -79.402828  43.643715    3.0          114        4   \n",
       "49353    175   230     1.0 -79.402828  43.643715    3.0          114        4   \n",
       "49354    175   349     1.0 -79.402828  43.643715    3.0          114        4   \n",
       "\n",
       "       existEdge  \n",
       "0           True  \n",
       "1           True  \n",
       "2           True  \n",
       "3           True  \n",
       "4           True  \n",
       "...          ...  \n",
       "49350       True  \n",
       "49351       True  \n",
       "49352       True  \n",
       "49353       True  \n",
       "49354       True  \n",
       "\n",
       "[49355 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace place ids to integers ids\n",
    "placesId = dfGraphNodes['index'].to_dict()\n",
    "# print(placesId)\n",
    "\n",
    "# for index,place in placesId.items():\n",
    "#     dfGraph.replace({'index':{place:index}},inplace=True)\n",
    "#     dfGraph.replace({'edge':{place:index}},inplace=True)\n",
    "\n",
    "dfGraph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db97936",
   "metadata": {},
   "source": [
    "Acima foi uma tentativa de usar os ids das ligações de nós (origem e destino) para a predição, ai transformei os ids dos nós em ids numéricos para o algoritmo tentar interpretar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7eb24952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "torch.Size([49355])\n",
      "torch.Size([49355, 5])\n",
      "Training data:\n",
      "torch.Size([39484, 5])\n",
      "torch.Size([39484])\n",
      "Test data:\n",
      "torch.Size([9871, 5])\n",
      "torch.Size([9871])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {}\".format(device))\n",
    "\n",
    "focus = dfGraph['existEdge']\n",
    "data = dfGraph.iloc[:,[3,4,5,6,7]]\n",
    "data = data.astype({\"stars\": float, \"reviewCount\": int})\n",
    "\n",
    "\n",
    "Y_tensor = torch.tensor(focus)\n",
    "X_tensor = torch.tensor(data.to_numpy())\n",
    "print(Y_tensor.shape)\n",
    "print(X_tensor.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, Y_tensor, test_size = 0.20, random_state=5)\n",
    "\n",
    "print(\"Training data:\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"Test data:\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Cast fields to float to avoid compatibility problems\n",
    "X_train = X_train.float().to(device)\n",
    "y_train = y_train.float().to(device)\n",
    "X_test = X_test.float().to(device)\n",
    "y_test = y_test.float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f30e40",
   "metadata": {},
   "source": [
    "Transformação do dataframe em dados para o treinamento, aqui foram testadas várias combinações de features, mas nenhuma demonstrou ganho significante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2be8d97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features: 5\n",
      "Feedforward(\n",
      "  (fc1): Linear(in_features=5, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (fc4): Linear(in_features=20, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (out_act): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#input = num_features (número de features), e hidden size = 20 (número de neurôneos na camada escondida)\n",
    "num_features = X_train.shape[1]\n",
    "print(\"num_features: \"+str(num_features))\n",
    "\n",
    "model = Feedforward(num_features, 20).to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# lr = Learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67441d8c",
   "metadata": {},
   "source": [
    "Foi testado outro algoritmo a não ser o MSELoss mas tbm sem ganhos significantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be8be463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste - perda antes do treinamento 0.0026627075858414173\n",
      "Epoch 0: perda treino: 0.002692868933081627\n",
      "Epoch 1: perda treino: 0.0012824563309550285\n",
      "Epoch 2: perda treino: 0.000654550502076745\n",
      "Epoch 3: perda treino: 0.0003609405248425901\n",
      "Epoch 4: perda treino: 0.0002126830368069932\n",
      "Epoch 5: perda treino: 0.00013247194874566048\n",
      "Epoch 6: perda treino: 8.654539124108851e-05\n",
      "Epoch 7: perda treino: 5.895810681977309e-05\n",
      "Epoch 8: perda treino: 4.16621332988143e-05\n",
      "Epoch 9: perda treino: 3.0403969503822736e-05\n",
      "Epoch 10: perda treino: 2.2820693629910238e-05\n",
      "Epoch 11: perda treino: 1.75602672243258e-05\n",
      "Epoch 12: perda treino: 1.3814094018016476e-05\n",
      "Epoch 13: perda treino: 1.1085472578997724e-05\n",
      "Epoch 14: perda treino: 9.05930846784031e-06\n",
      "Teste - perda depois do treinamento 7.511731382692233e-06\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred = model(X_test)\n",
    "before_train = criterion(y_pred, y_test) \n",
    "print('Teste - perda antes do treinamento' , before_train.item())\n",
    "\n",
    "model.train()\n",
    "epoch = 15\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    y_pred = model(X_train)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    print('Epoch {}: perda treino: {}'.format(epoch, loss.item()))\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # update pass\n",
    "    optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "y_pred = model(X_test)\n",
    "after_train = criterion(y_pred, y_test)\n",
    "print('Teste - perda depois do treinamento' , after_train.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae22cbc9",
   "metadata": {},
   "source": [
    "O treinamento da rede ao meu ver estava estranho, pois já iniciava com valor de perda extremamente baixo, depois aumentava um pouco e depois voltava ao inicial praticamente, por isso estava testando com poucas epocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce1a1bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10598 entries, 0 to 10597\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   index        10598 non-null  object \n",
      " 1   edge         10598 non-null  object \n",
      " 2   longitude    10598 non-null  float64\n",
      " 3   latitude     10598 non-null  float64\n",
      " 4   stars        10598 non-null  object \n",
      " 5   reviewCount  10598 non-null  object \n",
      " 6   cluster      10598 non-null  int64  \n",
      " 7   weight       10598 non-null  int64  \n",
      "dtypes: float64(2), int64(2), object(4)\n",
      "memory usage: 662.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# print(X_test)\n",
    "# print(y_pred)\n",
    "# print(after_train)\n",
    "\n",
    "#Links to be evaluated\n",
    "dfEdgesToEvaluate = pd.read_csv('edgesToEvaluateTest.csv')\n",
    "dfEdgesToEvaluate = dfEdgesToEvaluate.rename(columns={'venue1': 'index', 'venue2':'edge'})\n",
    "dfEdgesToEvaluate.set_index('index',inplace=True)\n",
    "\n",
    "# print(dfEdgesToEvaluate)\n",
    "dfNodesToCopy = dfGraphNodes.copy()\n",
    "dfNodesToCopy.set_index('index',inplace=True)\n",
    "# print(dfNodesToCopy)\n",
    "\n",
    "dfToTest = pd.merge(dfEdgesToEvaluate, dfNodesToCopy, on='index')\n",
    "dfToTest.reset_index(inplace=True)\n",
    "dfToTest.drop('linkID',axis=1,inplace=True)\n",
    "\n",
    "# for index,place in placesId.items():\n",
    "#     dfToTest.replace({'index':{place:index}},inplace=True)\n",
    "#     dfToTest.replace({'edge':{place:index}},inplace=True)\n",
    "\n",
    "dfToTest['weight'] = 0\n",
    "\n",
    "dfToTest.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be6f740",
   "metadata": {},
   "source": [
    "Após treinamento, apliquei para validação nos dados fornecidos, porém infelizmente não obtive resultados expressivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef55964b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data:\n",
      "torch.Size([10598, 5])\n",
      "torch.Size([10598, 1])\n"
     ]
    }
   ],
   "source": [
    "# focus = dfToTest['existEdge']\n",
    "# Same column order\n",
    "data = dfToTest.iloc[:,[2,3,4,5,6]]\n",
    "data = data.astype({\"stars\": float, \"reviewCount\": int})\n",
    "\n",
    "# print(focus)\n",
    "# print(data.info())\n",
    "# print(dfGraph.columns)\n",
    "\n",
    "Y_tensor_eval = torch.zeros(len(dfEdgesToEvaluate),1)\n",
    "X_tensor_eval = torch.tensor(data.to_numpy())\n",
    "\n",
    "print(\"Test data:\")\n",
    "print(X_tensor_eval.shape)\n",
    "print(Y_tensor_eval.shape)\n",
    "\n",
    "# Cast fields to float to avoid compatibility problems\n",
    "X_tensor_eval = X_tensor_eval.float().to(device)\n",
    "Y_tensor_eval = Y_tensor_eval.float().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee999f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste - usando dados do treinamento 0.996825098991394\n",
      "10598\n",
      "[[0.99718106]\n",
      " [0.99718106]\n",
      " [0.99718106]\n",
      " ...\n",
      " [0.9984682 ]\n",
      " [0.9996439 ]\n",
      " [0.99993277]]\n",
      "10598\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linkID</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jniApOOS8ppUHhESL7OzTg</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gyFYZV4b_9TxG1ulQNi0Ig</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVUOj74lBgogrdKcNQH_zQ</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3HwoIoJcV7yDi3RV7T-oDQ</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84JCu-4LvE6SDAglrJztGA</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pz13Ru_-U4qoZiu89ezVmQ</th>\n",
       "      <td>10593</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e41TP5cXZqSrz50xCBJqZw</th>\n",
       "      <td>10594</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PyIF7dcDPNpfmi8ks-sKOQ</th>\n",
       "      <td>10595</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_T8qy9XAKAFLJdmoLg1Q-g</th>\n",
       "      <td>10596</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fy6srT4KpbE7ICBLdypEuQ</th>\n",
       "      <td>10597</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10598 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        linkID  link\n",
       "index                               \n",
       "jniApOOS8ppUHhESL7OzTg       0     1\n",
       "gyFYZV4b_9TxG1ulQNi0Ig       1     1\n",
       "KVUOj74lBgogrdKcNQH_zQ       2     1\n",
       "3HwoIoJcV7yDi3RV7T-oDQ       3     1\n",
       "84JCu-4LvE6SDAglrJztGA       4     1\n",
       "...                        ...   ...\n",
       "Pz13Ru_-U4qoZiu89ezVmQ   10593     1\n",
       "e41TP5cXZqSrz50xCBJqZw   10594     1\n",
       "PyIF7dcDPNpfmi8ks-sKOQ   10595     1\n",
       "_T8qy9XAKAFLJdmoLg1Q-g   10596     1\n",
       "fy6srT4KpbE7ICBLdypEuQ   10597     1\n",
       "\n",
       "[10598 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred = model(X_tensor_eval)\n",
    "after_train = criterion(y_pred, Y_tensor_eval) \n",
    "print('Teste - usando dados do treinamento' , after_train.item())\n",
    "\n",
    "# print(len(y_pred))\n",
    "# print(y_pred)\n",
    "\n",
    "exitData = y_pred.detach().numpy()\n",
    "print(len(exitData))\n",
    "print(exitData)\n",
    "\n",
    "binaryExit = np.where(exitData > 0, 1, 0)\n",
    "print(len(binaryExit))\n",
    "print(binaryExit)\n",
    "dfEdgesToEvaluate['link'] = binaryExit\n",
    "\n",
    "# dfEdgesToEvaluate.set_index('linkID',inplace=True)\n",
    "dfEdgesToEvaluate.drop(['edge'],axis=1,inplace=True,errors='ignore')\n",
    "\n",
    "dfEdgesToEvaluate.to_csv(\"edgesToEvaluateAnswers.csv\", columns=['linkID','link'],index=False) \n",
    "dfEdgesToEvaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdce38ff",
   "metadata": {},
   "source": [
    "Preparação do arquivo para upload na kaggle, não consegui identificar o motivo das respostas ficarem sempre 1 ou 0, sem meios termos"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
